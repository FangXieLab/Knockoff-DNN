{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlotte\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import NeuralNet, train_model, predict,ProximalSGD,accuracy\n",
    "from knockoff import create_knockoff_variable\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    #Set the parameters are consistent when the model is initialized\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "relevant_features = 33\n",
    "hidden_size_data = 264\n",
    "hidden_size = 264\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(input_size=input_size, relevant_features=relevant_features, hidden_size=hidden_size_data, \n",
    "                output_size=output_size, n_samples=1000, threshold=0.5):  \n",
    "    np.random.seed(42)\n",
    "\n",
    "    X_relevant = np.random.normal(loc=2, scale=3, size=(n_samples, relevant_features))  # mean=2, std=3\n",
    "\n",
    "    X_non_relevant = np.random.normal(loc=0, scale=1, size=(n_samples, input_size - relevant_features))  # mean=0, std=1\n",
    "\n",
    "    X_all = np.hstack([X_relevant, X_non_relevant])\n",
    "\n",
    "    layer_sizes = [relevant_features, hidden_size, output_size]  # Use only the relevant features\n",
    "    X_relevant_tensor = torch.tensor(X_relevant, dtype=torch.float32)\n",
    "    \n",
    "    set_seed(42)\n",
    "    model = NeuralNet(layer_sizes)\n",
    "    y_neural_network = model(X_relevant_tensor)\n",
    "\n",
    "    threshold = 0.5\n",
    "    y_binary_neural_network = (y_neural_network > threshold).float()\n",
    "\n",
    "    data = pd.DataFrame(X_all, columns=[f'var{i}' for i in range(input_size)])\n",
    "    data['y'] = y_binary_neural_network\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create knockoff variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "# X= (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    " \n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "knockoff_creator = create_knockoff_variable()\n",
    "X_knockoff = knockoff_creator.get_equi_features(X)\n",
    "# X_knockoff = (X_knockoff - X_knockoff.min(axis=0)) / (X_knockoff.max(axis=0) - X_knockoff.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_k91</th>\n",
       "      <th>var_k92</th>\n",
       "      <th>var_k93</th>\n",
       "      <th>var_k94</th>\n",
       "      <th>var_k95</th>\n",
       "      <th>var_k96</th>\n",
       "      <th>var_k97</th>\n",
       "      <th>var_k98</th>\n",
       "      <th>var_k99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.490142</td>\n",
       "      <td>1.585207</td>\n",
       "      <td>3.943066</td>\n",
       "      <td>6.569090</td>\n",
       "      <td>1.297540</td>\n",
       "      <td>1.297589</td>\n",
       "      <td>6.737638</td>\n",
       "      <td>4.302304</td>\n",
       "      <td>0.591577</td>\n",
       "      <td>3.627680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034453</td>\n",
       "      <td>-0.033122</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>-0.021628</td>\n",
       "      <td>-0.011788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.173133</td>\n",
       "      <td>4.467635</td>\n",
       "      <td>-1.662531</td>\n",
       "      <td>2.626591</td>\n",
       "      <td>-3.879010</td>\n",
       "      <td>-1.984558</td>\n",
       "      <td>2.590584</td>\n",
       "      <td>4.215400</td>\n",
       "      <td>2.514105</td>\n",
       "      <td>1.653055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>-0.017316</td>\n",
       "      <td>-0.037129</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>0.017278</td>\n",
       "      <td>-0.044893</td>\n",
       "      <td>-0.012170</td>\n",
       "      <td>-0.014179</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.783970</td>\n",
       "      <td>5.010599</td>\n",
       "      <td>3.084908</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>3.084187</td>\n",
       "      <td>6.614110</td>\n",
       "      <td>1.892522</td>\n",
       "      <td>6.693931</td>\n",
       "      <td>-5.859235</td>\n",
       "      <td>4.465708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041876</td>\n",
       "      <td>-0.001015</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>-0.031441</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>-0.008180</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.296239</td>\n",
       "      <td>-2.246112</td>\n",
       "      <td>0.738064</td>\n",
       "      <td>0.971856</td>\n",
       "      <td>-0.406832</td>\n",
       "      <td>1.516143</td>\n",
       "      <td>3.212153</td>\n",
       "      <td>7.658558</td>\n",
       "      <td>2.523733</td>\n",
       "      <td>2.772651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>-0.006697</td>\n",
       "      <td>0.046907</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>-0.069256</td>\n",
       "      <td>-0.060775</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>-0.050740</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.186911</td>\n",
       "      <td>3.420777</td>\n",
       "      <td>-0.758273</td>\n",
       "      <td>6.649803</td>\n",
       "      <td>-0.349760</td>\n",
       "      <td>1.033815</td>\n",
       "      <td>4.440552</td>\n",
       "      <td>-1.692593</td>\n",
       "      <td>2.682380</td>\n",
       "      <td>5.921428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>-0.019230</td>\n",
       "      <td>0.042395</td>\n",
       "      <td>0.017645</td>\n",
       "      <td>-0.007764</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.068749</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4.696002</td>\n",
       "      <td>2.741676</td>\n",
       "      <td>-1.148678</td>\n",
       "      <td>1.928387</td>\n",
       "      <td>3.311065</td>\n",
       "      <td>4.967817</td>\n",
       "      <td>-0.266136</td>\n",
       "      <td>0.324411</td>\n",
       "      <td>-0.085480</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012493</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>-0.015299</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.013542</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.079991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.934903</td>\n",
       "      <td>-0.155047</td>\n",
       "      <td>-2.510018</td>\n",
       "      <td>2.145360</td>\n",
       "      <td>-0.389681</td>\n",
       "      <td>5.962420</td>\n",
       "      <td>2.450440</td>\n",
       "      <td>3.686309</td>\n",
       "      <td>1.253634</td>\n",
       "      <td>2.603841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>-0.018075</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.888585</td>\n",
       "      <td>-2.833761</td>\n",
       "      <td>3.428247</td>\n",
       "      <td>8.701166</td>\n",
       "      <td>0.081406</td>\n",
       "      <td>1.493770</td>\n",
       "      <td>1.641565</td>\n",
       "      <td>4.959406</td>\n",
       "      <td>3.216717</td>\n",
       "      <td>4.761038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>-0.023652</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>0.028833</td>\n",
       "      <td>-0.063052</td>\n",
       "      <td>-0.089730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-3.534689</td>\n",
       "      <td>5.589999</td>\n",
       "      <td>2.585586</td>\n",
       "      <td>2.846564</td>\n",
       "      <td>4.301271</td>\n",
       "      <td>5.790931</td>\n",
       "      <td>1.930940</td>\n",
       "      <td>5.529655</td>\n",
       "      <td>3.656409</td>\n",
       "      <td>0.033253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>-0.027570</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.049369</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.038264</td>\n",
       "      <td>-0.031197</td>\n",
       "      <td>-0.019243</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-2.444976</td>\n",
       "      <td>2.327212</td>\n",
       "      <td>-0.267854</td>\n",
       "      <td>-5.858515</td>\n",
       "      <td>1.757349</td>\n",
       "      <td>3.553053</td>\n",
       "      <td>5.533116</td>\n",
       "      <td>7.270564</td>\n",
       "      <td>3.952807</td>\n",
       "      <td>4.800702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.040215</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>-0.075995</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0    3.490142  1.585207  3.943066  6.569090  1.297540  1.297589  6.737638   \n",
       "1   -1.173133  4.467635 -1.662531  2.626591 -3.879010 -1.984558  2.590584   \n",
       "2    1.783970  5.010599  3.084908  0.064641  3.084187  6.614110  1.892522   \n",
       "3    1.296239 -2.246112  0.738064  0.971856 -0.406832  1.516143  3.212153   \n",
       "4   -1.186911  3.420777 -0.758273  6.649803 -0.349760  1.033815  4.440552   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  4.696002  2.741676 -1.148678  1.928387  3.311065  4.967817 -0.266136   \n",
       "996  0.934903 -0.155047 -2.510018  2.145360 -0.389681  5.962420  2.450440   \n",
       "997  1.888585 -2.833761  3.428247  8.701166  0.081406  1.493770  1.641565   \n",
       "998 -3.534689  5.589999  2.585586  2.846564  4.301271  5.790931  1.930940   \n",
       "999 -2.444976  2.327212 -0.267854 -5.858515  1.757349  3.553053  5.533116   \n",
       "\n",
       "         var7      var8      var9  ...   var_k91   var_k92   var_k93  \\\n",
       "0    4.302304  0.591577  3.627680  ...  0.034453 -0.033122  0.018492   \n",
       "1    4.215400  2.514105  1.653055  ...  0.022673 -0.017316 -0.037129   \n",
       "2    6.693931 -5.859235  4.465708  ... -0.041876 -0.001015  0.016521   \n",
       "3    7.658558  2.523733  2.772651  ...  0.002618 -0.006697  0.046907   \n",
       "4   -1.692593  2.682380  5.921428  ...  0.024444  0.002415 -0.019230   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.324411 -0.085480  0.063439  ... -0.012493  0.008497 -0.015299   \n",
       "996  3.686309  1.253634  2.603841  ...  0.029264  0.012612 -0.030472   \n",
       "997  4.959406  3.216717  4.761038  ...  0.010602 -0.023652  0.040607   \n",
       "998  5.529655  3.656409  0.033253  ...  0.014154 -0.027570  0.006346   \n",
       "999  7.270564  3.952807  4.800702  ...  0.017892  0.006856  0.019447   \n",
       "\n",
       "      var_k94   var_k95   var_k96   var_k97   var_k98   var_k99    y  \n",
       "0   -0.000316 -0.025200  0.023365  0.009972 -0.021628 -0.011788  0.0  \n",
       "1   -0.008989  0.017278 -0.044893 -0.012170 -0.014179  0.006181  0.0  \n",
       "2    0.041242 -0.031441  0.024462  0.024236 -0.008180  0.007144  1.0  \n",
       "3    0.012209 -0.069256 -0.060775  0.052254 -0.050740  0.000170  0.0  \n",
       "4    0.042395  0.017645 -0.007764 -0.000105 -0.068749  0.015619  1.0  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "995  0.001296 -0.013542  0.010613 -0.001350  0.007365  0.079991  1.0  \n",
       "996 -0.018075  0.026242 -0.006903  0.000686  0.012208  0.012369  1.0  \n",
       "997  0.008429 -0.052465 -0.006947  0.028833 -0.063052 -0.089730  1.0  \n",
       "998 -0.000620 -0.049369  0.021905  0.038264 -0.031197 -0.019243  1.0  \n",
       "999  0.040215  0.027755  0.015541 -0.028571 -0.075995  0.010920  0.0  \n",
       "\n",
       "[1000 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_knockoff_df = pd.DataFrame(X_knockoff,columns= [f'var_k{i}' for i in range(input_size)])\n",
    "feature = pd.concat([X,X_knockoff_df],axis = 1)\n",
    "dataset1 =  pd.concat([feature,data['y']],axis = 1)\n",
    "dataset1\n",
    "# dataset1.to_csv(\"Simulationdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_W1(lambda_array,num_x):\n",
    "    row_sums1 = np.sum(lambda_array, axis=1)\n",
    "    W1 = []\n",
    "    for i in range(0,int(0.5*len(row_sums1)),1):\n",
    "        if row_sums1[i]>=row_sums1[i+num_x]:\n",
    "            W1.append(row_sums1[i])\n",
    "        else:\n",
    "            W1.append(-row_sums1[i+num_x])\n",
    "    return W1,row_sums1\n",
    "\n",
    "def compute_W2(model, row_sums1, num_x):\n",
    "    para = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and 'weight' in name:\n",
    "            para.append(param.data)\n",
    "\n",
    "\n",
    "    result = para[0]\n",
    "    for i in range(1, len(para)):\n",
    "        if i == (len(para) - 1):\n",
    "            result = torch.matmul(result.t(), para[i].reshape(-1, 1))\n",
    "        else:\n",
    "            result = torch.matmul(result.t(), para[i])\n",
    "    \n",
    "    g =[]\n",
    "    for i in range(len(result)):\n",
    "        g.append(result[i][0].cpu().numpy() * row_sums1[i]*10)\n",
    "  \n",
    "    W2= []\n",
    " \n",
    "    for i in range(0,int(0.5*len(g)),1):\n",
    "        W2.append(abs(g[i])-abs(g[i+num_x]))\n",
    "    return W2,g\n",
    "\n",
    "def select_variables(W,target_q):\n",
    "    T = []\n",
    "    for i in W:\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        t = abs(i)\n",
    "        for j in W:\n",
    "            if j < -t:\n",
    "                count1 = count1+1\n",
    "    \n",
    "            if j >= t:\n",
    "                count2 = count2 +1\n",
    "        q = (count1)/(max(count2,1))\n",
    "\n",
    "        if q <= target_q:\n",
    "            T.append(t)\n",
    "    threshold = min(T)\n",
    "    selected_vars = [i+1 for i in range(len(W)) if W[i] >= threshold]\n",
    "    return selected_vars, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [19:06<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Selected Variables: [1, 2, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 22, 23, 26, 27, 29, 32, 42, 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [18:39<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Selected Variables: [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 31, 32, 56, 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [3:11:21<00:00, 51.48s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Selected Variables: [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 42, 56, 62, 86, 95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:39<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Selected Variables: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 42, 81, 85, 90, 98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:21<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 - Selected Variables: [1, 5, 6, 7, 8, 9, 12, 13, 14, 16, 17, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:31<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 - Selected Variables: [1, 2, 5, 6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 22, 23, 25, 26, 27, 28, 29, 30, 33, 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:26<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 - Selected Variables: [2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 26, 27, 29, 31, 32, 33, 35, 64, 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:22<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8 - Selected Variables: [1, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 39, 69, 80, 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:32<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9 - Selected Variables: [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 26, 27, 29, 31, 32, 37, 39, 79, 81, 91, 94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [17:42<00:00,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10 - Selected Variables: [1, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 23, 26, 27, 29, 30, 31, 32, 33, 47, 80, 91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y.apply(pd.to_numeric, errors='coerce')\n",
    "y_float = (Y.values).astype(float) \n",
    "Y_tensor = torch.tensor(y_float, dtype=torch.float32).view(-1, 1).to(device)\n",
    "feature_tensor = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "c = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "# Y_tensor = Y_tensor.view(-1, 1) \n",
    "lambda_all = []\n",
    "all_selected_vars = []\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "\n",
    "for n in range(10):\n",
    "    lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "    for i in tqdm(np.arange(0,0.02,0.00009)):\n",
    "        net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "        optimizer = ProximalSGD(net1.parameters(), lr=0.01, l1_lambda=i)\n",
    "        train_model(net1, feature_tensor, Y_tensor, criterion, optimizer, epochs=50)\n",
    "        weight = next(net1.named_parameters())[1].data.t()\n",
    "        for j in range(len(lambda_array1)):\n",
    "            for k in range(len(lambda_array1[j])):\n",
    "                if abs(weight[j][k])==0 and lambda_array1[j][k] == 0:\n",
    "                    lambda_array1[j][k] = i\n",
    "    lambda_all.append(lambda_array1)\n",
    "    W1, _ = compute_W1(lambda_array1, input_size)\n",
    "    selected_vars, _ = select_variables(W1, 0.1)\n",
    "    print(f\"Model {n + 1} - Selected Variables:\", selected_vars)\n",
    "    all_selected_vars.append(selected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected variables and their counts:\n",
      "Variable: 5, Count: 10\n",
      "Variable: 6, Count: 10\n",
      "Variable: 8, Count: 10\n",
      "Variable: 9, Count: 10\n",
      "Variable: 12, Count: 10\n",
      "Variable: 13, Count: 10\n",
      "Variable: 14, Count: 10\n",
      "Variable: 17, Count: 10\n",
      "Variable: 23, Count: 10\n",
      "Variable: 26, Count: 10\n",
      "Variable: 27, Count: 10\n",
      "Variable: 29, Count: 10\n",
      "Variable: 19, Count: 9\n",
      "Variable: 32, Count: 9\n",
      "Variable: 1, Count: 8\n",
      "Variable: 22, Count: 8\n",
      "Variable: 15, Count: 8\n",
      "Variable: 31, Count: 8\n",
      "Variable: 2, Count: 7\n",
      "Variable: 7, Count: 7\n",
      "Variable: 33, Count: 7\n",
      "Variable: 20, Count: 6\n",
      "Variable: 21, Count: 6\n",
      "Variable: 3, Count: 5\n",
      "Variable: 4, Count: 5\n",
      "Variable: 30, Count: 5\n",
      "Variable: 10, Count: 4\n",
      "Variable: 18, Count: 4\n",
      "Variable: 42, Count: 3\n",
      "Variable: 25, Count: 3\n",
      "Variable: 16, Count: 3\n",
      "Variable: 11, Count: 3\n",
      "Variable: 28, Count: 3\n",
      "Variable: 56, Count: 2\n",
      "Variable: 24, Count: 2\n",
      "Variable: 81, Count: 2\n",
      "Variable: 90, Count: 2\n",
      "Variable: 39, Count: 2\n",
      "Variable: 80, Count: 2\n",
      "Variable: 91, Count: 2\n",
      "Variable: 43, Count: 1\n",
      "Variable: 88, Count: 1\n",
      "Variable: 62, Count: 1\n",
      "Variable: 86, Count: 1\n",
      "Variable: 95, Count: 1\n",
      "Variable: 85, Count: 1\n",
      "Variable: 98, Count: 1\n",
      "Variable: 40, Count: 1\n",
      "Variable: 35, Count: 1\n",
      "Variable: 64, Count: 1\n",
      "Variable: 74, Count: 1\n",
      "Variable: 69, Count: 1\n",
      "Variable: 37, Count: 1\n",
      "Variable: 79, Count: 1\n",
      "Variable: 94, Count: 1\n",
      "Variable: 47, Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_selected_vars(all_vars):\n",
    "    flat_vars = [item for sublist in all_vars for item in sublist]\n",
    "    var_counts = Counter(flat_vars)\n",
    "    sorted_vars = sorted(var_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_vars\n",
    "final_selected_vars = aggregate_selected_vars(all_selected_vars)\n",
    "\n",
    "\n",
    "print(\"Final selected variables and their counts:\")\n",
    "for var, count in final_selected_vars:\n",
    "    print(f\"Variable: {var}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Selected Variables: [4, 7, 12, 14, 17, 20, 23, 24, 25, 27, 28, 29, 31, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Selected Variables: [6, 7, 10, 11, 12, 14, 15, 16, 18, 19, 23, 25, 27, 28, 29, 30, 31, 32, 33, 68, 72, 77, 82, 93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:24<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Selected Variables: [3, 4, 6, 7, 11, 12, 14, 17, 18, 19, 23, 25, 26, 27, 28, 29, 45, 59, 61, 85, 99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:24<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Selected Variables: [6, 7, 10, 11, 14, 17, 22, 23, 27, 29, 30, 31, 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:21<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 - Selected Variables: [6, 10, 12, 14, 16, 17, 19, 20, 24, 28, 29, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:57<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 - Selected Variables: [6, 11, 14, 17, 23, 27, 29, 66, 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:23<00:00,  8.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 - Selected Variables: [2, 10, 11, 12, 14, 16, 17, 19, 27, 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:17<00:00,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8 - Selected Variables: [3, 6, 7, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 52, 65, 66, 69, 80, 98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9 - Selected Variables: [2, 4, 6, 7, 10, 12, 14, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 32, 69, 77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10 - Selected Variables: [2, 3, 4, 6, 12, 14, 17, 19, 23, 25, 27, 29, 32, 67, 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y.apply(pd.to_numeric, errors='coerce')\n",
    "y_float = (Y.values).astype(float) \n",
    "Y_tensor = torch.tensor(y_float, dtype=torch.float32).view(-1, 1).to(device)\n",
    "feature_tensor = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "c = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "# Y_tensor = Y_tensor.view(-1, 1) \n",
    "lambda_all = []\n",
    "all_selected_vars = []\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "\n",
    "for n in range(10):\n",
    "    lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "    for i in tqdm(np.arange(0, 0.1, 0.01)):\n",
    "        #(0,0.09,0.0009\n",
    "        net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "        optimizer = ProximalSGD(net1.parameters(), lr=0.01, l1_lambda=i)\n",
    "        train_model(net1, feature_tensor, Y_tensor, criterion, optimizer, epochs=50)\n",
    "        weight = next(net1.named_parameters())[1].data.t()\n",
    "        for j in range(len(lambda_array1)):\n",
    "            for k in range(len(lambda_array1[j])):\n",
    "                if abs(weight[j][k])==0 and lambda_array1[j][k] == 0:\n",
    "                    lambda_array1[j][k] = i\n",
    "    lambda_all.append(lambda_array1)\n",
    "    W1, row_sums1 = compute_W1(lambda_all[n],input_size)\n",
    "    W2, _ = compute_W2(net1,row_sums1,input_size)\n",
    "    selected_vars, _ = select_variables(W2, 0.1)\n",
    "    print(f\"Model {n + 1} - Selected Variables:\", selected_vars)\n",
    "    all_selected_vars.append(selected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected variables and their counts:\n",
      "Variable: 14, Count: 10\n",
      "Variable: 27, Count: 9\n",
      "Variable: 29, Count: 9\n",
      "Variable: 12, Count: 8\n",
      "Variable: 17, Count: 8\n",
      "Variable: 23, Count: 8\n",
      "Variable: 6, Count: 8\n",
      "Variable: 7, Count: 6\n",
      "Variable: 25, Count: 6\n",
      "Variable: 28, Count: 6\n",
      "Variable: 32, Count: 6\n",
      "Variable: 10, Count: 6\n",
      "Variable: 11, Count: 6\n",
      "Variable: 19, Count: 6\n",
      "Variable: 31, Count: 5\n",
      "Variable: 16, Count: 5\n",
      "Variable: 4, Count: 4\n",
      "Variable: 18, Count: 4\n",
      "Variable: 30, Count: 4\n",
      "Variable: 20, Count: 3\n",
      "Variable: 33, Count: 3\n",
      "Variable: 3, Count: 3\n",
      "Variable: 2, Count: 3\n",
      "Variable: 24, Count: 2\n",
      "Variable: 77, Count: 2\n",
      "Variable: 22, Count: 2\n",
      "Variable: 66, Count: 2\n",
      "Variable: 69, Count: 2\n",
      "Variable: 15, Count: 1\n",
      "Variable: 68, Count: 1\n",
      "Variable: 72, Count: 1\n",
      "Variable: 82, Count: 1\n",
      "Variable: 93, Count: 1\n",
      "Variable: 26, Count: 1\n",
      "Variable: 45, Count: 1\n",
      "Variable: 59, Count: 1\n",
      "Variable: 61, Count: 1\n",
      "Variable: 85, Count: 1\n",
      "Variable: 99, Count: 1\n",
      "Variable: 88, Count: 1\n",
      "Variable: 52, Count: 1\n",
      "Variable: 65, Count: 1\n",
      "Variable: 80, Count: 1\n",
      "Variable: 98, Count: 1\n",
      "Variable: 21, Count: 1\n",
      "Variable: 67, Count: 1\n",
      "Variable: 73, Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_selected_vars(all_vars):\n",
    "    flat_vars = [item for sublist in all_vars for item in sublist]\n",
    "    var_counts = Counter(flat_vars)\n",
    "    sorted_vars = sorted(var_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_vars\n",
    "final_selected_vars = aggregate_selected_vars(all_selected_vars)\n",
    "\n",
    "\n",
    "print(\"Final selected variables and their counts:\")\n",
    "for var, count in final_selected_vars:\n",
    "    print(f\"Variable: {var}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### OML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable: 5, Count: 10\n",
    "Variable: 6, Count: 18\n",
    "Variable: 8, Count: 10\n",
    "Variable: 9, Count: 10\n",
    "Variable: 12, Count: 18\n",
    "Variable: 13, Count: 10\n",
    "Variable: 14, Count: 20\n",
    "Variable: 17, Count: 18\n",
    "Variable: 23, Count: 18\n",
    "Variable: 26, Count: 11\n",
    "Variable: 27, Count: 19\n",
    "Variable: 29, Count: 19\n",
    "Variable: 19, Count: 15\n",
    "Variable: 32, Count: 15\n",
    "Variable: 1, Count: 8\n",
    "Variable: 22, Count: 10\n",
    "Variable: 15, Count: 9\n",
    "Variable: 31, Count: 13\n",
    "Variable: 2, Count: 10\n",
    "Variable: 7, Count: 13\n",
    "Variable: 33, Count: 10\n",
    "Variable: 20, Count: 9\n",
    "Variable: 21, Count: 7\n",
    "Variable: 3, Count: 8\n",
    "Variable: 4, Count: 9\n",
    "Variable: 30, Count: 9\n",
    "Variable: 10, Count: 10\n",
    "Variable: 18, Count: 8\n",
    "Variable: 25, Count: 9\n",
    "Variable: 16, Count: 8\n",
    "Variable: 11, Count: 9\n",
    "Variable: 28, Count: 9\n",
    "Variable: 42, Count: 3\n",
    "Variable: 56, Count: 2\n",
    "Variable: 24, Count: 4\n",
    "Variable: 81, Count: 2\n",
    "Variable: 90, Count: 2\n",
    "Variable: 39, Count: 2\n",
    "Variable: 80, Count: 2\n",
    "Variable: 91, Count: 2\n",
    "Variable: 43, Count: 1\n",
    "Variable: 88, Count: 1\n",
    "Variable: 62, Count: 1\n",
    "Variable: 86, Count: 1\n",
    "Variable: 95, Count: 1\n",
    "Variable: 85, Count: 1\n",
    "Variable: 98, Count: 1\n",
    "Variable: 40, Count: 1\n",
    "Variable: 35, Count: 1\n",
    "Variable: 64, Count: 1\n",
    "Variable: 74, Count: 1\n",
    "Variable: 69, Count: 1\n",
    "Variable: 37, Count: 1\n",
    "Variable: 79, Count: 1\n",
    "Variable: 94, Count: 1\n",
    "Variable: 47, Count: 1\n",
    "Variable: 77, Count: 2\n",
    "Variable: 66, Count: 2\n",
    "Variable: 69, Count: 2\n",
    "Variable: 68, Count: 1\n",
    "Variable: 72, Count: 1\n",
    "Variable: 82, Count: 1\n",
    "Variable: 93, Count: 1\n",
    "Variable: 45, Count: 1\n",
    "Variable: 59, Count: 1\n",
    "Variable: 61, Count: 1\n",
    "Variable: 85, Count: 1\n",
    "Variable: 99, Count: 1\n",
    "Variable: 88, Count: 1\n",
    "Variable: 52, Count: 1\n",
    "Variable: 65, Count: 1\n",
    "Variable: 80, Count: 1\n",
    "Variable: 98, Count: 1\n",
    "Variable: 67, Count: 1\n",
    "Variable: 73, Count: 1\n",
    "\n",
    "OL: 0 0.79\n",
    "ML: 0 0.48\n",
    "OML: 0 0.97"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
