{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       var0      var1      var2      var3      var4      var5      var6  \\\n",
      "0  0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
      "1 -1.057711  0.822545 -1.220844  0.208864 -1.959670 -1.328186  0.196861   \n",
      "2 -0.072010  1.003533  0.361636 -0.645120  0.361396  1.538037 -0.035826   \n",
      "3 -0.234587 -1.415371 -0.420645 -0.342715 -0.802277 -0.161286  0.404051   \n",
      "4 -1.062304  0.473592 -0.919424  1.549934 -0.783253 -0.322062  0.813517   \n",
      "\n",
      "       var7      var8      var9  ...     var91     var92     var93     var94  \\\n",
      "0  0.767435 -0.469474  0.542560  ... -0.029352  0.395307  0.033023  1.346941   \n",
      "1  0.738467  0.171368 -0.115648  ...  1.021963  0.733179  1.378143 -0.990623   \n",
      "2  1.564644 -2.619745  0.821903  ...  0.272634  0.342226 -1.098679  0.044570   \n",
      "3  1.886186  0.174578  0.257550  ... -1.312467  0.536389 -1.671147 -0.838362   \n",
      "4 -1.230864  0.227460  1.307143  ...  0.534347 -1.768415  0.995168  0.937367   \n",
      "\n",
      "      var95     var96     var97     var98     var99  y  \n",
      "0  0.774023 -0.007481  0.216689  0.295666  0.403300  1  \n",
      "1 -0.343192  0.758982  0.448078  1.532380  0.420537  0  \n",
      "2  0.631224 -1.151227  1.104997 -0.377531  1.257613  1  \n",
      "3 -1.212657  0.781943 -0.065410 -0.013503 -1.106733  0  \n",
      "4  0.830161  0.372842  0.220189  1.032389  1.923513  0  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.normal(loc=0, scale=1, size=(input_size, hidden_size))\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.normal(loc=0, scale=1, size=(hidden_size, output_size))\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    Z1 = np.dot(X, parameters['W1']) + parameters['b1']\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, parameters['W2']) + parameters['b2']\n",
    "    A2 = sigmoid(Z2)\n",
    "    return {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n",
    "\n",
    "def predict(X, parameters):\n",
    "    forward = forward_propagation(X, parameters)\n",
    "    return (forward['A2'] > 0.5).astype(int)\n",
    "\n",
    "# Set up neural network parameters\n",
    "input_size = 100\n",
    "hidden_size = 264\n",
    "output_size = 1\n",
    "\n",
    "# Generate random input data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate the first 33 variables using the neural network\n",
    "X_first_33 = np.random.normal(loc=0, scale=1, size=(n_samples, 33))\n",
    "parameters = initialize_parameters(33, hidden_size, output_size)\n",
    "forward = forward_propagation(X_first_33, parameters)\n",
    "y_neural_network = forward['A2']\n",
    "\n",
    "# Generate random values for the remaining variables\n",
    "X_rest = np.random.normal(loc=0, scale=1, size=(n_samples, input_size - 33))\n",
    "\n",
    "# Combine the generated values\n",
    "X = np.concatenate((X_first_33, X_rest), axis=1)\n",
    "\n",
    "# Threshold for binary classification\n",
    "threshold = 0.5\n",
    "y_binary_neural_network = (y_neural_network > threshold).astype(int)\n",
    "\n",
    "# Add the generated y values to the existing DataFrame\n",
    "data = pd.DataFrame(X, columns=[f'var{i}' for i in range(input_size)])\n",
    "data['y'] = y_binary_neural_network\n",
    "\n",
    "# Print the DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_prediction(X_train,y_train,X_test,y_test,input_s):\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc= []\n",
    "    for i in range(0,10,1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(264, input_shape=(input_dim,)))\n",
    "\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train,y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)  \n",
    "        accuracy = accuracy_score(y_test, predicted)  \n",
    "     \n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_out_prediction(X_train,y_train,X_test,y_test,input_s):\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc= []\n",
    "    for i in range(0,10,1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(264, activation='relu', input_shape=(input_dim,)))\n",
    "        model.add(layers.Dropout(0.33))  # Adding dropout with rate 0.5\n",
    "\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)\n",
    "        accuracy = accuracy_score(y_test, predicted)  \n",
    "        # 输出准确率\n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_varaibles_prediction(X_train,y_train,X_test,y_test,input_s):\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc= []\n",
    "    for i in range(0,10,1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(264, input_shape=(input_dim,)))\n",
    "\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train,y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)  \n",
    "        accuracy = accuracy_score(y_test, predicted)  \n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:02:49.081646Z",
     "iopub.status.busy": "2023-12-07T09:02:49.081187Z",
     "iopub.status.idle": "2023-12-07T09:06:33.509009Z",
     "shell.execute_reply": "2023-12-07T09:06:33.508102Z",
     "shell.execute_reply.started": "2023-12-07T09:02:49.081612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 10.429088878631593 s\n",
      "Average accuracy: 78.25 %\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 11.922840666770934 s\n",
      "Average accuracy: 77.60000000000001 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "var_t = data.loc[:, ['var1','var6','var7','var10','var16','var20','var23','var24','var26','var27','var30','var31','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var1','var6','var7','var10','var16','var20','var23','var24','var26','var27','var30','var31']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['var0','var3','var6','var10','var19','var20','var23','var24','var25','var26','var27','var31','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var0','var3','var6','var10','var19','var20','var23','var24','var25','var26','var27','var31']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 975us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 6.518034982681274 s\n",
      "Average accuracy: 77.2 %\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 9.463358306884766 s\n",
      "Average accuracy: 71.89999999999999 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA_OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "var_t = data.loc[:, ['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29', 'y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 6.825684976577759 s\n",
      "Average accuracy: 70.64999999999999 %\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 998us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 8.113622045516967 s\n",
      "Average accuracy: 67.4 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data[['var13', 'var26', 'var28', 'var11', 'var16', 'var22','var5', 'var6', 'var24', 'var27', 'var31', 'var9', 'var10', 'var18', 'var30', 'var15','y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var13', 'var26', 'var28', 'var11', 'var16', 'var22','var5', 'var6', 'var24', 'var27', 'var31', 'var9', 'var10', 'var18', 'var30', 'var15']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 390us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 6.25473906993866 s\n",
      "Average accuracy: 75.2 %\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 998us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Average running time: 8.157733392715453 s\n",
      "Average accuracy: 70.35 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA_OML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29','var9','var17','var24','var15','var10','var27','y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29','var9','var17','var24','var15','var10','var27']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 841us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Average running time: 6.737831783294678 s\n",
      "Average accuracy: 80.35 %\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 919us/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Average running time: 8.89448983669281 s\n",
      "Average accuracy: 80.05000000000001 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:21:25.758612Z",
     "iopub.status.busy": "2023-12-07T09:21:25.758287Z",
     "iopub.status.idle": "2023-12-07T09:26:05.412988Z",
     "shell.execute_reply": "2023-12-07T09:26:05.410841Z",
     "shell.execute_reply.started": "2023-12-07T09:21:25.758583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 11.214705634117127 s\n",
      "Average accuracy: 75.85 %\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 16.673228645324706 s\n",
      "Average accuracy: 76.7 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "\n",
    "normal_prediction(X_train,y_train,X_test,y_test,100)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       var0      var1      var2      var3      var4      var5      var6  \\\n",
      "0  0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
      "1 -1.057711  0.822545 -1.220844  0.208864 -1.959670 -1.328186  0.196861   \n",
      "2 -0.072010  1.003533  0.361636 -0.645120  0.361396  1.538037 -0.035826   \n",
      "3 -0.234587 -1.415371 -0.420645 -0.342715 -0.802277 -0.161286  0.404051   \n",
      "4 -1.062304  0.473592 -0.919424  1.549934 -0.783253 -0.322062  0.813517   \n",
      "\n",
      "       var7      var8      var9  ...     var91     var92     var93     var94  \\\n",
      "0  0.767435 -0.469474  0.542560  ... -0.029352  0.395307  0.033023  1.346941   \n",
      "1  0.738467  0.171368 -0.115648  ...  1.021963  0.733179  1.378143 -0.990623   \n",
      "2  1.564644 -2.619745  0.821903  ...  0.272634  0.342226 -1.098679  0.044570   \n",
      "3  1.886186  0.174578  0.257550  ... -1.312467  0.536389 -1.671147 -0.838362   \n",
      "4 -1.230864  0.227460  1.307143  ...  0.534347 -1.768415  0.995168  0.937367   \n",
      "\n",
      "      var95     var96     var97     var98     var99  y  \n",
      "0  0.774023 -0.007481  0.216689  0.295666  0.403300  1  \n",
      "1 -0.343192  0.758982  0.448078  1.532380  0.420537  0  \n",
      "2  0.631224 -1.151227  1.104997 -0.377531  1.257613  1  \n",
      "3 -1.212657  0.781943 -0.065410 -0.013503 -1.106733  0  \n",
      "4  0.830161  0.372842  0.220189  1.032389  1.923513  0  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature91_k</th>\n",
       "      <th>feature92_k</th>\n",
       "      <th>feature93_k</th>\n",
       "      <th>feature94_k</th>\n",
       "      <th>feature95_k</th>\n",
       "      <th>feature96_k</th>\n",
       "      <th>feature97_k</th>\n",
       "      <th>feature98_k</th>\n",
       "      <th>feature99_k</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453366</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>0.663988</td>\n",
       "      <td>1.511999</td>\n",
       "      <td>-0.240969</td>\n",
       "      <td>-0.185356</td>\n",
       "      <td>1.560560</td>\n",
       "      <td>0.743297</td>\n",
       "      <td>-0.458107</td>\n",
       "      <td>0.563718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.392953</td>\n",
       "      <td>1.328734</td>\n",
       "      <td>1.097952</td>\n",
       "      <td>-1.648306</td>\n",
       "      <td>-0.165183</td>\n",
       "      <td>-0.295485</td>\n",
       "      <td>1.555953</td>\n",
       "      <td>0.450022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.109920</td>\n",
       "      <td>0.784452</td>\n",
       "      <td>-1.211126</td>\n",
       "      <td>0.209216</td>\n",
       "      <td>-2.000063</td>\n",
       "      <td>-1.263838</td>\n",
       "      <td>0.205948</td>\n",
       "      <td>0.713553</td>\n",
       "      <td>0.175235</td>\n",
       "      <td>-0.106240</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.257662</td>\n",
       "      <td>0.584329</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>0.088015</td>\n",
       "      <td>0.811433</td>\n",
       "      <td>-0.093714</td>\n",
       "      <td>-0.411926</td>\n",
       "      <td>-1.560464</td>\n",
       "      <td>-1.211231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.118600</td>\n",
       "      <td>0.961859</td>\n",
       "      <td>0.376928</td>\n",
       "      <td>-0.637370</td>\n",
       "      <td>0.366168</td>\n",
       "      <td>1.561602</td>\n",
       "      <td>-0.022070</td>\n",
       "      <td>1.561837</td>\n",
       "      <td>-2.583211</td>\n",
       "      <td>0.848047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468241</td>\n",
       "      <td>-0.052013</td>\n",
       "      <td>0.457419</td>\n",
       "      <td>-0.172570</td>\n",
       "      <td>0.144992</td>\n",
       "      <td>-0.755030</td>\n",
       "      <td>1.420825</td>\n",
       "      <td>-1.423810</td>\n",
       "      <td>-0.385982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.282104</td>\n",
       "      <td>-1.409187</td>\n",
       "      <td>-0.408109</td>\n",
       "      <td>-0.337584</td>\n",
       "      <td>-0.820148</td>\n",
       "      <td>-0.113541</td>\n",
       "      <td>0.408980</td>\n",
       "      <td>1.891982</td>\n",
       "      <td>0.178407</td>\n",
       "      <td>0.273621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331501</td>\n",
       "      <td>0.656186</td>\n",
       "      <td>2.651308</td>\n",
       "      <td>-0.119277</td>\n",
       "      <td>0.542618</td>\n",
       "      <td>-0.168797</td>\n",
       "      <td>-1.109217</td>\n",
       "      <td>-0.220027</td>\n",
       "      <td>0.592296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.114539</td>\n",
       "      <td>0.442404</td>\n",
       "      <td>-0.908645</td>\n",
       "      <td>1.538670</td>\n",
       "      <td>-0.800754</td>\n",
       "      <td>-0.272030</td>\n",
       "      <td>0.810230</td>\n",
       "      <td>-1.308471</td>\n",
       "      <td>0.230670</td>\n",
       "      <td>1.341950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>-0.954020</td>\n",
       "      <td>-0.558327</td>\n",
       "      <td>1.151677</td>\n",
       "      <td>-0.407388</td>\n",
       "      <td>1.156443</td>\n",
       "      <td>0.255484</td>\n",
       "      <td>1.752459</td>\n",
       "      <td>-0.637515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.857611</td>\n",
       "      <td>0.220515</td>\n",
       "      <td>-1.039238</td>\n",
       "      <td>-0.021502</td>\n",
       "      <td>0.443266</td>\n",
       "      <td>1.020646</td>\n",
       "      <td>-0.727184</td>\n",
       "      <td>-0.618147</td>\n",
       "      <td>-0.681152</td>\n",
       "      <td>-0.645571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880521</td>\n",
       "      <td>0.561123</td>\n",
       "      <td>-0.187615</td>\n",
       "      <td>0.590897</td>\n",
       "      <td>0.717976</td>\n",
       "      <td>2.216450</td>\n",
       "      <td>0.774594</td>\n",
       "      <td>1.206445</td>\n",
       "      <td>-1.988576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.403236</td>\n",
       "      <td>-0.725955</td>\n",
       "      <td>-1.494617</td>\n",
       "      <td>0.050196</td>\n",
       "      <td>-0.814320</td>\n",
       "      <td>1.347463</td>\n",
       "      <td>0.160171</td>\n",
       "      <td>0.532471</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>0.216346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350321</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>1.331181</td>\n",
       "      <td>1.359493</td>\n",
       "      <td>1.556090</td>\n",
       "      <td>-0.303557</td>\n",
       "      <td>-0.798531</td>\n",
       "      <td>2.443395</td>\n",
       "      <td>0.733447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.083530</td>\n",
       "      <td>-1.601194</td>\n",
       "      <td>0.491777</td>\n",
       "      <td>2.216535</td>\n",
       "      <td>-0.654236</td>\n",
       "      <td>-0.120893</td>\n",
       "      <td>-0.104044</td>\n",
       "      <td>0.968191</td>\n",
       "      <td>0.406698</td>\n",
       "      <td>0.948248</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.277865</td>\n",
       "      <td>-0.544419</td>\n",
       "      <td>-1.085406</td>\n",
       "      <td>-0.664075</td>\n",
       "      <td>0.716933</td>\n",
       "      <td>0.124159</td>\n",
       "      <td>0.569351</td>\n",
       "      <td>0.567875</td>\n",
       "      <td>2.840357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.901593</td>\n",
       "      <td>1.151172</td>\n",
       "      <td>0.209901</td>\n",
       "      <td>0.281905</td>\n",
       "      <td>0.779757</td>\n",
       "      <td>1.291113</td>\n",
       "      <td>-0.009521</td>\n",
       "      <td>1.163360</td>\n",
       "      <td>0.551546</td>\n",
       "      <td>-0.655813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264692</td>\n",
       "      <td>0.593664</td>\n",
       "      <td>-0.352553</td>\n",
       "      <td>-0.286219</td>\n",
       "      <td>-0.385229</td>\n",
       "      <td>1.095248</td>\n",
       "      <td>-0.840813</td>\n",
       "      <td>-2.369916</td>\n",
       "      <td>-0.260249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.536284</td>\n",
       "      <td>0.085094</td>\n",
       "      <td>-0.744596</td>\n",
       "      <td>-2.594653</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>0.555768</td>\n",
       "      <td>1.167110</td>\n",
       "      <td>1.759191</td>\n",
       "      <td>0.649189</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.376488</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>0.253618</td>\n",
       "      <td>-0.048451</td>\n",
       "      <td>0.096247</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.824296</td>\n",
       "      <td>-0.075594</td>\n",
       "      <td>2.074133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0    0.453366 -0.157348  0.663988  1.511999 -0.240969 -0.185356  1.560560   \n",
       "1   -1.109920  0.784452 -1.211126  0.209216 -2.000063 -1.263838  0.205948   \n",
       "2   -0.118600  0.961859  0.376928 -0.637370  0.366168  1.561602 -0.022070   \n",
       "3   -0.282104 -1.409187 -0.408109 -0.337584 -0.820148 -0.113541  0.408980   \n",
       "4   -1.114539  0.442404 -0.908645  1.538670 -0.800754 -0.272030  0.810230   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.857611  0.220515 -1.039238 -0.021502  0.443266  1.020646 -0.727184   \n",
       "996 -0.403236 -0.725955 -1.494617  0.050196 -0.814320  1.347463  0.160171   \n",
       "997 -0.083530 -1.601194  0.491777  2.216535 -0.654236 -0.120893 -0.104044   \n",
       "998 -1.901593  1.151172  0.209901  0.281905  0.779757  1.291113 -0.009521   \n",
       "999 -1.536284  0.085094 -0.744596 -2.594653 -0.084717  0.555768  1.167110   \n",
       "\n",
       "         var7      var8      var9  ...  feature91_k  feature92_k  feature93_k  \\\n",
       "0    0.743297 -0.458107  0.563718  ...     0.999163     0.392953     1.328734   \n",
       "1    0.713553  0.175235 -0.106240  ...    -1.257662     0.584329    -0.096528   \n",
       "2    1.561837 -2.583211  0.848047  ...     0.468241    -0.052013     0.457419   \n",
       "3    1.891982  0.178407  0.273621  ...    -0.331501     0.656186     2.651308   \n",
       "4   -1.308471  0.230670  1.341950  ...     0.019434    -0.954020    -0.558327   \n",
       "..        ...       ...       ...  ...          ...          ...          ...   \n",
       "995 -0.618147 -0.681152 -0.645571  ...     0.880521     0.561123    -0.187615   \n",
       "996  0.532471 -0.240005  0.216346  ...    -0.350321     0.211602     1.331181   \n",
       "997  0.968191  0.406698  0.948248  ...    -1.277865    -0.544419    -1.085406   \n",
       "998  1.163360  0.551546 -0.655813  ...     0.264692     0.593664    -0.352553   \n",
       "999  1.759191  0.649189  0.961705  ...    -1.376488     0.059348     0.253618   \n",
       "\n",
       "     feature94_k  feature95_k  feature96_k  feature97_k  feature98_k  \\\n",
       "0       1.097952    -1.648306    -0.165183    -0.295485     1.555953   \n",
       "1       0.088015     0.811433    -0.093714    -0.411926    -1.560464   \n",
       "2      -0.172570     0.144992    -0.755030     1.420825    -1.423810   \n",
       "3      -0.119277     0.542618    -0.168797    -1.109217    -0.220027   \n",
       "4       1.151677    -0.407388     1.156443     0.255484     1.752459   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "995     0.590897     0.717976     2.216450     0.774594     1.206445   \n",
       "996     1.359493     1.556090    -0.303557    -0.798531     2.443395   \n",
       "997    -0.664075     0.716933     0.124159     0.569351     0.567875   \n",
       "998    -0.286219    -0.385229     1.095248    -0.840813    -2.369916   \n",
       "999    -0.048451     0.096247     0.019663     0.824296    -0.075594   \n",
       "\n",
       "     feature99_k  y  \n",
       "0       0.450022  1  \n",
       "1      -1.211231  0  \n",
       "2      -0.385982  1  \n",
       "3       0.592296  0  \n",
       "4      -0.637515  0  \n",
       "..           ... ..  \n",
       "995    -1.988576  1  \n",
       "996     0.733447  0  \n",
       "997     2.840357  1  \n",
       "998    -0.260249  1  \n",
       "999     2.074133  0  \n",
       "\n",
       "[1000 rows x 201 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.normal(loc=0, scale=1, size=(input_size, hidden_size))\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.normal(loc=0, scale=1, size=(hidden_size, output_size))\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    Z1 = np.dot(X, parameters['W1']) + parameters['b1']\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, parameters['W2']) + parameters['b2']\n",
    "    A2 = sigmoid(Z2)\n",
    "    return {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n",
    "\n",
    "def predict(X, parameters):\n",
    "    forward = forward_propagation(X, parameters)\n",
    "    return (forward['A2'] > 0.5).astype(int)\n",
    "\n",
    "# Set up neural network parameters\n",
    "input_size = 100\n",
    "hidden_size = 264\n",
    "output_size = 1\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate random input data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate the first 33 variables using the neural network\n",
    "X_first_33 = np.random.normal(loc=0, scale=1, size=(n_samples, 33))\n",
    "parameters = initialize_parameters(33, hidden_size, output_size)\n",
    "forward = forward_propagation(X_first_33, parameters)\n",
    "y_neural_network = forward['A2']\n",
    "\n",
    "# Generate random values for the remaining variables\n",
    "X_rest = np.random.normal(loc=0, scale=1,size=(n_samples, input_size - 33))\n",
    "\n",
    "# Combine the generated values\n",
    "X = np.concatenate((X_first_33, X_rest), axis=1)\n",
    "\n",
    "# Threshold for binary classification\n",
    "threshold =0.5\n",
    "y_binary_neural_network = (y_neural_network > threshold).astype(int)\n",
    "\n",
    "# Add the generated y values to the existing DataFrame\n",
    "data = pd.DataFrame(X, columns=[f'var{i}' for i in range(input_size)])\n",
    "data['y'] = y_binary_neural_network\n",
    "\n",
    "# Print the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "def reduce_weight(lambda_array1,lambda_array2,value,variables):\n",
    "    lambda_array2 = np.where(lambda_array2 == 0, 8, lambda_array2)\n",
    "#     print(lambda_array2)\n",
    "    layer1_weight = lambda_array1\n",
    "    layer2_weight = lambda_array2\n",
    "    layer1_weight = np.where(lambda_array1[:100, :] < value, 0, 1)\n",
    "    layer1_weight = layer1_weight[variables, :]\n",
    "    layer2_weight = np.where(lambda_array2[:264, :] < value, 0, 1)\n",
    "    \n",
    "    zero_count = 264*len(selected_vars1)+ 264 - np.count_nonzero(layer1_weight)-np.count_nonzero(layer2_weight)\n",
    "    rate = zero_count/(264*len(selected_vars1)+ 264)\n",
    "    return rate,layer1_weight,layer2_weight\n",
    "\n",
    "def reduce_weight_prediction(X_train,y_train,X_test,y_test,input_s, weight1, weight2):\n",
    "    # Assuming you have your custom weights for the first layer\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc = []\n",
    "    \n",
    "    custom_first_layer_weights = weight1  \n",
    "    custom_second_layer_weights = weight2  \n",
    "\n",
    "    for i in range(0, 10, 1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(Dense(264, activation='relu', input_shape=(input_dim,), weights=[custom_first_layer_weights, np.zeros(264)]))\n",
    "        model.add(Dense(1, activation='sigmoid', weights=[custom_second_layer_weights, np.zeros(1)]))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        def prune(model, threshold=100):\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, tf.keras.layers.Dense):\n",
    "                    weights = layer.get_weights()\n",
    "                    weights[0][np.abs(weights[0]) < threshold] = 0\n",
    "                    layer.set_weights(weights)\n",
    "        start_time = time.time()+1\n",
    "        model.fit(X_train, y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "## some useful functions\n",
    "def get_arccos(X):\n",
    "    # X is a 2-d array\n",
    "    n, p = X.shape\n",
    "    cos_a = np.zeros([n, n, n])\n",
    "    \n",
    "    for r in range(n):\n",
    "        \n",
    "        xr = X[r]\n",
    "        X_r = X - xr\n",
    "        cross = np.dot(X_r, X_r.T)\n",
    "        row_norm = np.sqrt(np.sum(X_r**2, axis = 1))\n",
    "        outer_norm = np.outer(row_norm, row_norm)\n",
    "        \n",
    "        zero_idx = (outer_norm == 0.)\n",
    "        outer_norm[zero_idx] = 1.\n",
    "        cos_a_kl = cross / outer_norm\n",
    "        cos_a_kl[zero_idx] = 0.\n",
    "\n",
    "        cos_a[:,:,r] = cos_a_kl\n",
    "        \n",
    "    cos_a[cos_a > 1] = 1.\n",
    "    cos_a[cos_a < -1] = -1.\n",
    "    a = np.arccos(cos_a)\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "        \n",
    "    return a, A\n",
    "\n",
    "def get_arccos_1d(X):\n",
    "    # X is a 1-d array\n",
    "    \n",
    "    X = np.squeeze(X)\n",
    "    Y = X[:,None] - X\n",
    "    Z = Y.T[:,:,None]*Y.T[:,None]\n",
    "    n = len(X)\n",
    "    \n",
    "    a = np.zeros([n, n, n])\n",
    "    a[Z == 0.] = np.pi/2.\n",
    "    a[Z < 0.] = np.pi\n",
    "    \n",
    "    a = np.transpose(a, (1,2,0))\n",
    "    \n",
    "    #a = Z[Z>0.]*0. + Z[Z==0.]*np.pi/2. + Z[Z<0.]*np.pi\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "    \n",
    "    return a, A\n",
    "\n",
    "def orthonormalize(X):\n",
    "    # X is a 2-d array\n",
    "    # output: Gram-Schmidt orthogonalization of X\n",
    "    \n",
    "    n, p = X.shape\n",
    "    Y = np.zeros([n,p])\n",
    "    Y[:,0] = X[:,0]/np.sqrt(np.sum(X[:,0]**2))\n",
    "    \n",
    "    for j in range(1,p):\n",
    "        \n",
    "        Yj = Y[:,range(j)]\n",
    "        xj = X[:,j]\n",
    "        w = np.dot(xj, Yj)\n",
    "        xj_p = np.sum(w*Yj, axis = 1)\n",
    "        yj = xj - xj_p\n",
    "        yj = yj/np.sqrt(np.sum(yj**2))\n",
    "        \n",
    "        Y[:,j] = yj\n",
    "        \n",
    "    return Y\n",
    "\n",
    "# Main functions\n",
    "def projection_corr(X, Y):\n",
    "    # X, Y are 2-d array\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def projection_corr_1d(X, Y):\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos_1d(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def projection_corr_1dy(X, Y):\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def get_equi_features(X):\n",
    "    # X is 2-d array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    scale = np.sqrt(np.sum(X**2, axis=0))\n",
    "    Xstd = X / scale\n",
    "    sigma = np.dot(Xstd.T, Xstd)\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    lambd_min = eigsh(sigma, k=1, which='SA')[0].squeeze()\n",
    "    sj = np.min([1., 2.*lambd_min])\n",
    "    sj = sj - 0.00001\n",
    "    \n",
    "    mat_s = np.diag([sj]*p)\n",
    "    A = 2*mat_s - sj*sj*sigma_inv\n",
    "    C = np.linalg.cholesky(A).T\n",
    "    \n",
    "    Xn = np.random.randn(n, p)\n",
    "    XX = np.hstack([Xstd, Xn])\n",
    "    XXo = orthonormalize(XX)\n",
    "    U = XXo[:,range(p,2*p)]\n",
    "    \n",
    "    Xnew = np.dot(Xstd,  np.eye(p) - sigma_inv*sj) + np.dot(U,C)\n",
    "    return Xnew\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "X = (X - X.mean()) / X.std()\n",
    "Y = data.iloc[:,-1]\n",
    "X_knockoff = get_equi_features(X)\n",
    "X_knockoff = (X_knockoff - X_knockoff.mean()) / X_knockoff.std()\n",
    "\n",
    "X_knockoff_df = pd.DataFrame(X_knockoff)\n",
    "column_names = ['feature0_k', 'feature1_k', 'feature2_k', 'feature3_k', 'feature4_k','feature5_k', 'feature6_k', 'feature7_k', 'feature8_k', 'feature9_k',\n",
    "                'feature10_k', 'feature11_k', 'feature12_k', 'feature13_k', 'feature14_k','feature15_k', 'feature16_k', 'feature17_k', 'feature18_k', 'feature19_k',\n",
    "                'feature20_k', 'feature21_k', 'feature22_k', 'feature23_k', 'feature24_k','feature25_k', 'feature26_k', 'feature27_k', 'feature28_k', 'feature29_k',\n",
    "                'feature30_k', 'feature31_k', 'feature32_k', 'feature33_k', 'feature34_k','feature35_k', 'feature36_k', 'feature37_k', 'feature38_k', 'feature39_k',\n",
    "                'feature40_k', 'feature41_k', 'feature42_k', 'feature43_k', 'feature44_k','feature45_k', 'feature46_k', 'feature47_k', 'feature48_k', 'feature49_k',\n",
    "                'feature50_k', 'feature51_k', 'feature52_k', 'feature53_k', 'feature54_k','feature55_k', 'feature56_k', 'feature57_k', 'feature58_k', 'feature59_k',\n",
    "                'feature60_k', 'feature61_k', 'feature62_k', 'feature63_k', 'feature64_k','feature65_k', 'feature66_k', 'feature67_k', 'feature68_k', 'feature69_k',\n",
    "                'feature70_k', 'feature71_k', 'feature72_k', 'feature73_k', 'feature74_k','feature75_k', 'feature76_k', 'feature77_k', 'feature78_k', 'feature79_k',\n",
    "                'feature80_k', 'feature81_k', 'feature82_k', 'feature83_k', 'feature84_k','feature85_k', 'feature86_k', 'feature87_k', 'feature88_k', 'feature89_k',\n",
    "                'feature90_k', 'feature91_k', 'feature92_k', 'feature93_k', 'feature94_k','feature95_k', 'feature96_k', 'feature97_k', 'feature98_k', 'feature99_k']\n",
    "X_knockoff_df.columns = column_names\n",
    "feature = pd.concat([X,X_knockoff_df],axis = 1)\n",
    "dataset1 =  pd.concat([feature,data['y']],axis = 1)\n",
    "dataset1\n",
    "# dataset1.to_csv('dataset2_for_DeepPINK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [10:03<00:00,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05 0.1  0.1  ... 0.05 0.2  0.05]\n",
      " [0.05 0.1  0.1  ... 0.05 0.2  0.05]\n",
      " [0.05 0.1  0.1  ... 0.05 0.2  0.05]\n",
      " ...\n",
      " [0.05 0.1  0.1  ... 0.05 0.2  0.05]\n",
      " [0.05 0.1  0.1  ... 0.05 0.05 0.05]\n",
      " [0.05 0.1  0.05 ... 0.05 0.2  0.05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "lambda_array = np.zeros((200, 264))\n",
    "lambda_array2 = np.zeros((264, 1))\n",
    "input_dim = 200\n",
    "\n",
    "# Use tqdm for a one-line progress bar\n",
    "for i in tqdm(np.arange(0, 7, 0.05)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(264, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i)))\n",
    "    #model.add(layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(feature, Y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    first_layer = model.layers[0]\n",
    "    weights, biases = first_layer.get_weights()\n",
    "    \n",
    "    for j in range(min(len(weights), len(lambda_array))):\n",
    "        for n in range(min(len(weights[j]), len(lambda_array[j]))):\n",
    "            if abs(weights[j][n]) < 5e-4 and lambda_array[j][n] == 0:\n",
    "                lambda_array[j][n] = i\n",
    "    \n",
    "    # Calculate the Zi in second layer\n",
    "    second_layer = model.layers[1]\n",
    "    weights, biases = second_layer.get_weights()\n",
    "    #print(f\"Layer: {layer.name}, Weights: {weights}\")\n",
    "#     print(weights)\n",
    "    for j in range(len(weights)):\n",
    "        for n in range(len(weights[j])):\n",
    "            if abs(weights[j][n]) < 5e-4 and lambda_array2[j][n] == 0 :\n",
    "#                 print(j,n)\n",
    "                lambda_array2[j][n] = i\n",
    "print(lambda_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32925407925407923"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = [1,6,7,10,16,20,23,24,26,27,30,31]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.1,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "var_t = data.loc[:, ['var1','var6','var7','var10','var16','var23','var24','var25','var26','var27','var30','var31','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var1','var6','var7','var10','var16','var23','var24','var25','var26','var27','var30','var31']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:37:50.334641Z",
     "iopub.status.busy": "2023-12-07T09:37:50.333673Z",
     "iopub.status.idle": "2023-12-07T09:39:35.620111Z",
     "shell.execute_reply": "2023-12-07T09:39:35.618940Z",
     "shell.execute_reply.started": "2023-12-07T09:37:50.334588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 9.491174840927124 s\n",
      "Average accuracy: 79.35000000000001 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,12, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:39:35.622085Z",
     "iopub.status.busy": "2023-12-07T09:39:35.621720Z",
     "iopub.status.idle": "2023-12-07T09:39:35.636517Z",
     "shell.execute_reply": "2023-12-07T09:39:35.635461Z",
     "shell.execute_reply.started": "2023-12-07T09:39:35.622054Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['var1','var6','var7','var10','var13','var16','var20','var23','var24','var26','var27','var30','var31','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var1','var6','var7','var10','var13','var16','var20','var23','var24','var26','var27','var30','var31']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:39:35.638250Z",
     "iopub.status.busy": "2023-12-07T09:39:35.637909Z",
     "iopub.status.idle": "2023-12-07T09:39:35.648062Z",
     "shell.execute_reply": "2023-12-07T09:39:35.646951Z",
     "shell.execute_reply.started": "2023-12-07T09:39:35.638222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35064935064935066"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = [0, 6, 7, 10, 13, 16, 20, 23, 24, 26, 27, 30,31]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.1,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:39:35.649802Z",
     "iopub.status.busy": "2023-12-07T09:39:35.649509Z",
     "iopub.status.idle": "2023-12-07T09:41:20.972338Z",
     "shell.execute_reply": "2023-12-07T09:41:20.971054Z",
     "shell.execute_reply.started": "2023-12-07T09:39:35.649776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 9.49518554210663 s\n",
      "Average accuracy: 79.60000000000001 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,13, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "var_t = data.loc[:, ['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29', 'y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3547979797979798"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = [4, 5, 7, 8, 11, 12, 13, 16, 22, 25, 26, 28, 18, 31, 0, 21, 14, 30, 1, 6, 32, 19, 20, 2, 3, 29]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.1,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 6.9524836301803585 s\n",
      "Average accuracy: 71.2 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,26, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data[['var13', 'var26', 'var28', 'var11', 'var16', 'var22','var5', 'var6', 'var24', 'var27', 'var31', 'var9', 'var10', 'var18', 'var30', 'var15','y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var13', 'var26', 'var28', 'var11', 'var16', 'var22','var5', 'var6', 'var24', 'var27', 'var31', 'var9', 'var10', 'var18', 'var30', 'var15']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34157754010695185"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = [13, 26, 28, 11, 16, 22, 5, 6, 24, 27, 31, 9, 10, 18, 30, 15]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.10,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 5.657754492759705 s\n",
      "Average accuracy: 76.89999999999999 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,16, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_OML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35651974288337923"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = [4, 5, 7, 8, 11, 12, 13, 16, 22, 25, 26, 28, 18, 31, 0, 21, 14, 30, 1, 6, 32, 19, 20, 2, 3, 29, 9, 17, 24, 15, 10, 27]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.1,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29','var9','var17','var24','var15','var10','var27','y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var4', 'var5', 'var7', 'var8', 'var11', 'var12', 'var13', 'var16', 'var22', 'var25', 'var26', 'var28', 'var18', 'var31', 'var0', 'var21', 'var14',\n",
    "                      'var30', 'var1', 'var6', 'var32', 'var19', 'var20', 'var2', 'var3', 'var29','var9','var17','var24','var15','var10','var27']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 5.5468226909637455 s\n",
      "Average accuracy: 79.89999999999999 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,32, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T11:41:03.557575Z",
     "iopub.status.busy": "2023-12-07T11:41:03.557173Z",
     "iopub.status.idle": "2023-12-07T11:41:03.567202Z",
     "shell.execute_reply": "2023-12-07T11:41:03.565794Z",
     "shell.execute_reply.started": "2023-12-07T11:41:03.557542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39723972397239726"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vars1 = []\n",
    "for i in range(100):\n",
    "    selected_vars1.append(i)\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0.1,selected_vars1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T11:46:48.580192Z",
     "iopub.status.busy": "2023-12-07T11:46:48.579724Z",
     "iopub.status.idle": "2023-12-07T11:48:49.048233Z",
     "shell.execute_reply": "2023-12-07T11:48:49.047091Z",
     "shell.execute_reply.started": "2023-12-07T11:46:48.580158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 11.00966272354126 s\n",
      "Average accuracy: 75.35 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "\n",
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,100, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:46:41.411861Z",
     "iopub.status.busy": "2023-12-07T09:46:41.411460Z",
     "iopub.status.idle": "2023-12-07T09:46:41.428215Z",
     "shell.execute_reply": "2023-12-07T09:46:41.427035Z",
     "shell.execute_reply.started": "2023-12-07T09:46:41.411828Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data[['var0', 'var1', 'var5','var6', 'var7', 'var16','var22', 'var23','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var0', 'var1', 'var5','var6', 'var7', 'var16','var22', 'var23'\n",
    "]], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:46:41.430442Z",
     "iopub.status.busy": "2023-12-07T09:46:41.429899Z",
     "iopub.status.idle": "2023-12-07T09:48:26.767396Z",
     "shell.execute_reply": "2023-12-07T09:48:26.766173Z",
     "shell.execute_reply.started": "2023-12-07T09:46:41.430396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 10.497719120979308 s\n",
      "Average accuracy: 67.10000000000001 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:48:26.769222Z",
     "iopub.status.busy": "2023-12-07T09:48:26.768841Z",
     "iopub.status.idle": "2023-12-07T09:50:08.748152Z",
     "shell.execute_reply": "2023-12-07T09:50:08.746981Z",
     "shell.execute_reply.started": "2023-12-07T09:48:26.769189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 10.160671019554139 s\n",
      "Average accuracy: 63.05 %\n"
     ]
    }
   ],
   "source": [
    "var_t = data[['var9', 'var11', 'var13','var96','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var9', 'var11', 'var13','var96'\n",
    "]], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepPINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:08.752256Z",
     "iopub.status.busy": "2023-12-07T09:50:08.751299Z",
     "iopub.status.idle": "2023-12-07T09:51:52.171598Z",
     "shell.execute_reply": "2023-12-07T09:51:52.170629Z",
     "shell.execute_reply.started": "2023-12-07T09:50:08.752204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Average running time: 10.305346179008485 s\n",
      "Average accuracy: 67.5 %\n"
     ]
    }
   ],
   "source": [
    "var_t = data[['var27', 'var43', 'var55','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var27', 'var43', 'var55']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "    \n",
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T11:00:39.948852Z",
     "iopub.status.busy": "2023-12-07T11:00:39.948352Z",
     "iopub.status.idle": "2023-12-07T11:02:25.266635Z",
     "shell.execute_reply": "2023-12-07T11:02:25.265336Z",
     "shell.execute_reply.started": "2023-12-07T11:00:39.948816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Average running time: 10.4948894739151 s\n",
      "Average accuracy: 65.25000000000001 %\n"
     ]
    }
   ],
   "source": [
    "var_t = data[['var10', 'var45', 'var20', 'var23','y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['var10', 'var45', 'var20', 'var23']], var_t['y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "    \n",
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
