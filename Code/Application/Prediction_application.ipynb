{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from model import NeuralNet, train_model, predict,ProximalSGD,accuracy\n",
    "#from knockoff import create_knockoff_variable\n",
    "# # import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "input_size = 30\n",
    "hidden_size_data = 60\n",
    "hidden_size = 60\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius1  texture1  perimeter1     area1  smoothness1  compactness1  \\\n",
       "0    0.521037  0.022658    0.545989  0.363733     0.593753      0.792037   \n",
       "1    0.643144  0.272574    0.615783  0.501591     0.289880      0.181768   \n",
       "2    0.601496  0.390260    0.595743  0.449417     0.514309      0.431017   \n",
       "3    0.210090  0.360839    0.233501  0.102906     0.811321      0.811361   \n",
       "4    0.629893  0.156578    0.630986  0.489290     0.430351      0.347893   \n",
       "..        ...       ...         ...       ...          ...           ...   \n",
       "564  0.690000  0.428813    0.678668  0.566490     0.526948      0.296055   \n",
       "565  0.622320  0.626987    0.604036  0.474019     0.407782      0.257714   \n",
       "566  0.455251  0.621238    0.445788  0.303118     0.288165      0.254340   \n",
       "567  0.644564  0.663510    0.665538  0.475716     0.588336      0.790197   \n",
       "568  0.036869  0.501522    0.028540  0.015907     0.000000      0.074351   \n",
       "\n",
       "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n",
       "0      0.703140         0.731113   0.686364            0.605518  ...   \n",
       "1      0.203608         0.348757   0.379798            0.141323  ...   \n",
       "2      0.462512         0.635686   0.509596            0.211247  ...   \n",
       "3      0.565604         0.522863   0.776263            1.000000  ...   \n",
       "4      0.463918         0.518390   0.378283            0.186816  ...   \n",
       "..          ...              ...        ...                 ...  ...   \n",
       "564    0.571462         0.690358   0.336364            0.132056  ...   \n",
       "565    0.337395         0.486630   0.349495            0.113100  ...   \n",
       "566    0.216753         0.263519   0.267677            0.137321  ...   \n",
       "567    0.823336         0.755467   0.675253            0.425442  ...   \n",
       "568    0.000000         0.000000   0.266162            0.187026  ...   \n",
       "\n",
       "     texture3  perimeter3     area3  smoothness3  compactness3  concavity3  \\\n",
       "0    0.141525    0.668310  0.450698     0.601136      0.619292    0.568610   \n",
       "1    0.303571    0.539818  0.435214     0.347553      0.154563    0.192971   \n",
       "2    0.360075    0.508442  0.374508     0.483590      0.385375    0.359744   \n",
       "3    0.385928    0.241347  0.094008     0.915472      0.814012    0.548642   \n",
       "4    0.123934    0.506948  0.341575     0.437364      0.172415    0.319489   \n",
       "..        ...         ...       ...          ...           ...         ...   \n",
       "564  0.383262    0.576174  0.452664     0.461137      0.178527    0.328035   \n",
       "565  0.699094    0.520892  0.379915     0.300007      0.159997    0.256789   \n",
       "566  0.589019    0.379949  0.230731     0.282177      0.273705    0.271805   \n",
       "567  0.730277    0.668310  0.402035     0.619626      0.815758    0.749760   \n",
       "568  0.489072    0.043578  0.020497     0.124084      0.036043    0.000000   \n",
       "\n",
       "     concave_points3  symmetry3  fractal_dimension3  Y  \n",
       "0           0.912027   0.598462            0.418864  1  \n",
       "1           0.639175   0.233590            0.222878  1  \n",
       "2           0.835052   0.403706            0.213433  1  \n",
       "3           0.884880   1.000000            0.773711  1  \n",
       "4           0.558419   0.157500            0.142595  1  \n",
       "..               ...        ...                 ... ..  \n",
       "564         0.761512   0.097575            0.105667  1  \n",
       "565         0.559450   0.198502            0.074315  1  \n",
       "566         0.487285   0.128721            0.151909  1  \n",
       "567         0.910653   0.497142            0.452315  1  \n",
       "568         0.000000   0.257441            0.100682  0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('cancerdata_feature.csv')\n",
    "data = df.rename(columns={\n",
    "    'Column1': 'radius1', 'Column2': 'texture1', 'Column3': 'perimeter1', \n",
    "    'Column4': 'area1', 'Column5': 'smoothness1', 'Column6': 'compactness', \n",
    "    'Column7': 'concavity1', 'Column8': 'concave_points1', 'Column9': 'symmetry1', \n",
    "    'Column10': 'fractal_dimension1', 'Column11': 'radius2', 'Column12': 'texture2', \n",
    "    'Column13': 'perimeter2', 'Column14': 'area2', 'Column15': 'smoothness2', \n",
    "    'Column16': 'compactness2', 'Column17': 'concavity2', 'Column18': 'concave_points2',\n",
    "    'Column19': 'symmetry2', 'Column20': 'fractal_dimension2', 'Column21': 'radius3', \n",
    "    'Column22': 'texture3', 'Column23': 'perimeter3', 'Column24': 'area3', \n",
    "    'Column25': 'smoothness3', 'Column26': 'compactness3', 'Column27': 'concavity3', \n",
    "    'Column28': 'concave_points3', 'Column29': 'symmetry3', 'Column30': 'fractal_dimension3'\n",
    "})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n",
    "y_df = pd.read_csv('cancerdata_Y.csv')\n",
    "\n",
    "y_df['Y'] = y_df['Y'].replace({'B': 0, 'M': 1})\n",
    "\n",
    "data_normalized['Y'] = y_df['Y']\n",
    "data = data_normalized\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "# X= (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    " \n",
    "Y = data.iloc[:, -1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_prediction(X_train,y_train,X_test,y_test,input_s):\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc= []\n",
    "    for i in range(0,10,1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(60, input_shape=(input_dim,)))\n",
    "\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train,y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)  \n",
    "        accuracy = accuracy_score(y_test, predicted) \n",
    "       \n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_out_prediction(X_train,y_train,X_test,y_test,input_s):\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc= []\n",
    "    for i in range(0,10,1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(60, activation='relu', input_shape=(input_dim,)))\n",
    "        model.add(layers.Dropout(0.3))  # Adding dropout with rate 0.5\n",
    "\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)\n",
    "        accuracy = accuracy_score(y_test, predicted)  \n",
    "        # 输出准确率\n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinle layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:02:38.233777Z",
     "iopub.status.busy": "2023-12-07T09:02:38.233413Z",
     "iopub.status.idle": "2023-12-07T09:02:38.254629Z",
     "shell.execute_reply": "2023-12-07T09:02:38.253655Z",
     "shell.execute_reply.started": "2023-12-07T09:02:38.233746Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['concavity1','radius3', 'concavity3', 'fractal_dimension3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['concavity1','radius3', 'concavity3', 'fractal_dimension3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:02:38.256450Z",
     "iopub.status.busy": "2023-12-07T09:02:38.256019Z",
     "iopub.status.idle": "2023-12-07T09:04:59.188920Z",
     "shell.execute_reply": "2023-12-07T09:04:59.188016Z",
     "shell.execute_reply.started": "2023-12-07T09:02:38.256419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 6.583042287826538 s\n",
      "Average accuracy: 96.66666666666669 %\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 7.426801300048828 s\n",
      "Average accuracy: 97.10526315789473 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:04:59.191175Z",
     "iopub.status.busy": "2023-12-07T09:04:59.190517Z",
     "iopub.status.idle": "2023-12-07T09:04:59.204348Z",
     "shell.execute_reply": "2023-12-07T09:04:59.203352Z",
     "shell.execute_reply.started": "2023-12-07T09:04:59.191135Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['concavity1','concave_points1','radius3','texture3','concavity3', 'symmetry3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['concavity1','concave_points1','radius3','texture3','concavity3', 'symmetry3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:04:59.207070Z",
     "iopub.status.busy": "2023-12-07T09:04:59.206567Z",
     "iopub.status.idle": "2023-12-07T09:07:55.368634Z",
     "shell.execute_reply": "2023-12-07T09:07:55.367759Z",
     "shell.execute_reply.started": "2023-12-07T09:04:59.207023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 8.136424112319947 s\n",
      "Average accuracy: 94.73684210526315 %\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 9.408484387397767 s\n",
      "Average accuracy: 95.08771929824562 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:07:55.371242Z",
     "iopub.status.busy": "2023-12-07T09:07:55.370067Z",
     "iopub.status.idle": "2023-12-07T09:07:55.386020Z",
     "shell.execute_reply": "2023-12-07T09:07:55.385158Z",
     "shell.execute_reply.started": "2023-12-07T09:07:55.371197Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,2:], data['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:07:55.391963Z",
     "iopub.status.busy": "2023-12-07T09:07:55.391362Z",
     "iopub.status.idle": "2023-12-07T09:10:33.442247Z",
     "shell.execute_reply": "2023-12-07T09:10:33.440164Z",
     "shell.execute_reply.started": "2023-12-07T09:07:55.391903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 7.198666763305664 s\n",
      "Average accuracy: 97.98245614035088 %\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 8.53656725883484 s\n",
      "Average accuracy: 98.15789473684208 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,30)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "var_t = data.loc[:, ['texture1', 'smoothness3', 'concave_points2', 'symmetry2', 'radius3', 'perimeter3', 'concave_points3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['texture1', 'smoothness3', 'concave_points2', 'symmetry2', 'radius3', 'perimeter3', 'concave_points3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 4.6281705617904665 s\n",
      "Average accuracy: 97.6315789473684 %\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "Average running time: 4.96560492515564 s\n",
      "Average accuracy: 97.01754385964912 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['perimeter2', 'smoothness1','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['perimeter2', 'smoothness1']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 3.9398087739944456 s\n",
      "Average accuracy: 83.33333333333334 %\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 4.061375021934509 s\n",
      "Average accuracy: 82.80701754385966 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWA one & multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['texture1','smoothness2','concave_points2','symmetry2','radius3', 'perimeter3', 'concave_points3','perimeter1', 'concavity1','fractal_dimension1','smoothness3',\n",
    "'symmetry3','fractal_dimension3','concavity3', 'concave_points1','symmetry1','fractal_dimension2','area3', 'compactness3','smoothness1','area1','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['texture1','smoothness2','concave_points2','symmetry2','radius3', 'perimeter3', 'concave_points3','perimeter1', 'concavity1','fractal_dimension1','smoothness3',\n",
    "'symmetry3','fractal_dimension3','concavity3', 'concave_points1','symmetry1','fractal_dimension2','area3', 'compactness3','smoothness1','area1']],\n",
    "                                                    var_t['Y'], test_size=0.2, random_state=42)\n",
    "# X_train = (X_train.values).reshape(-1,1)\n",
    "# X_test = (X_test.values).reshape(-1, 1)\n",
    "input_data = []\n",
    "output_data = [] \n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 3.9846663236618043 s\n",
      "Average accuracy: 97.45614035087719 %\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "Average running time: 4.139012360572815 s\n",
      "Average accuracy: 97.19298245614034 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)\n",
    "drop_out_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:26<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03 0.09 0.05 ... 0.06 0.07 0.08]\n",
      " [0.03 0.09 0.05 ... 0.06 0.03 0.08]\n",
      " [0.03 0.09 0.05 ... 0.06 0.07 0.08]\n",
      " ...\n",
      " [0.03 0.01 0.05 ... 0.06 0.03 0.01]\n",
      " [0.02 0.02 0.05 ... 0.01 0.02 0.02]\n",
      " [0.01 0.02 0.01 ... 0.01 0.01 0.03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def reduce_weight(lambda_array1,lambda_array2,value,variables):\n",
    "    lambda_array2 = np.where(lambda_array2 == 0, 2, lambda_array2)\n",
    "#     print(lambda_array2)\n",
    "    layer1_weight = lambda_array1\n",
    "    layer2_weight = lambda_array2\n",
    "    layer1_weight = np.where(lambda_array1[:30, :] < value, 0, 1)\n",
    "    layer1_weight = layer1_weight[variables, :]\n",
    "    layer2_weight = np.where(lambda_array2[:60, :] < value, 0, 1)\n",
    "    \n",
    "    zero_count = 10*len(selected_vars1)+ 10 - np.count_nonzero(layer1_weight)-np.count_nonzero(layer2_weight)\n",
    "    rate = zero_count/(10*len(variables)+ 10)\n",
    "    return rate,layer1_weight,layer2_weight\n",
    "\n",
    "\n",
    "def reduce_weight_prediction(X_train,y_train,X_test,y_test,input_s, weight1, weight2):\n",
    "    # Assuming you have your custom weights for the first layer\n",
    "    input_dim = input_s\n",
    "    running_times = []\n",
    "    acc = []\n",
    "    \n",
    "    custom_first_layer_weights = weight1  \n",
    "    custom_second_layer_weights = weight2  \n",
    "\n",
    "    for i in range(0, 10, 1):\n",
    "        model = keras.Sequential()\n",
    "        model.add(Dense(60, activation='relu', input_shape=(input_dim,), weights=[custom_first_layer_weights, np.zeros(60)]))\n",
    "        model.add(Dense(1, activation='sigmoid', weights=[custom_second_layer_weights, np.zeros(1)]))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()+1\n",
    "        model.fit(X_train, y_train, epochs=250, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted = (predictions > 0.5)\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        running_times.append(run_time)\n",
    "        acc.append(accuracy)\n",
    "\n",
    "    avg_running_time = np.mean(running_times)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "\n",
    "    print(\"Average running time:\", avg_running_time, \"s\")\n",
    "    print(\"Average accuracy:\", avg_accuracy * 100, \"%\")\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "## some useful functions\n",
    "def get_arccos(X):\n",
    "    # X is a 2-d array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    cos_a = np.zeros([n, n, n])\n",
    "    \n",
    "    for r in range(n):\n",
    "        \n",
    "        xr = X[r]\n",
    "        X_r = X - xr\n",
    "        cross = np.dot(X_r, X_r.T)\n",
    "        row_norm = np.sqrt(np.sum(X_r**2, axis = 1))\n",
    "        outer_norm = np.outer(row_norm, row_norm)\n",
    "        \n",
    "        zero_idx = (outer_norm == 0.)\n",
    "        outer_norm[zero_idx] = 1.\n",
    "        cos_a_kl = cross / outer_norm\n",
    "        cos_a_kl[zero_idx] = 0.\n",
    "\n",
    "        cos_a[:,:,r] = cos_a_kl\n",
    "        \n",
    "    cos_a[cos_a > 1] = 1.\n",
    "    cos_a[cos_a < -1] = -1.\n",
    "    a = np.arccos(cos_a)\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "        \n",
    "    return a, A\n",
    "\n",
    "def get_arccos_1d(X):\n",
    "    # X is a 1-d array\n",
    "    \n",
    "    X = np.squeeze(X)\n",
    "    Y = X[:,None] - X\n",
    "    Z = Y.T[:,:,None]*Y.T[:,None]\n",
    "    n = len(X)\n",
    "    \n",
    "    a = np.zeros([n, n, n])\n",
    "    a[Z == 0.] = np.pi/2.\n",
    "    a[Z < 0.] = np.pi\n",
    "    \n",
    "    a = np.transpose(a, (1,2,0))\n",
    "    \n",
    "    #a = Z[Z>0.]*0. + Z[Z==0.]*np.pi/2. + Z[Z<0.]*np.pi\n",
    "\n",
    "    a_bar_12 = np.mean(a, axis = 0, keepdims = True)\n",
    "    a_bar_02 = np.mean(a, axis = 1, keepdims = True)\n",
    "    a_bar_2  = np.mean(a, axis = (0,1), keepdims = True)\n",
    "    A = a - a_bar_12 - a_bar_02 + a_bar_2\n",
    "    \n",
    "    return a, A\n",
    "\n",
    "def orthonormalize(X):\n",
    "    # X is a 2-d array\n",
    "    # output: Gram-Schmidt orthogonalization of X\n",
    "    \n",
    "    n, p = X.shape\n",
    "    Y = np.zeros([n,p])\n",
    "    Y[:,0] = X[:,0]/np.sqrt(np.sum(X[:,0]**2))\n",
    "    \n",
    "    for j in range(1,p):\n",
    "        \n",
    "        Yj = Y[:,range(j)]\n",
    "        xj = X[:,j]\n",
    "        w = np.dot(xj, Yj)\n",
    "        xj_p = np.sum(w*Yj, axis = 1)\n",
    "        yj = xj - xj_p\n",
    "        yj = yj/np.sqrt(np.sum(yj**2))\n",
    "        \n",
    "        Y[:,j] = yj\n",
    "        \n",
    "    return Y\n",
    "\n",
    "# Main functions\n",
    "def projection_corr(X, Y):\n",
    "    # X, Y are 2-d array\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def projection_corr_1d(X, Y):\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos_1d(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def projection_corr_1dy(X, Y):\n",
    "    \n",
    "    nx, p = X.shape\n",
    "    ny, q = Y.shape\n",
    "    \n",
    "    if nx == ny:\n",
    "        n = nx\n",
    "    else:\n",
    "        raise ValueError(\"sample sizes do not match.\")\n",
    "        \n",
    "    a_x, A_x = get_arccos(X)\n",
    "    a_y, A_y = get_arccos_1d(Y)\n",
    "    \n",
    "    S_xy = np.sum(A_x * A_y) / (n**3)\n",
    "    S_xx = np.sum(A_x**2) / (n**3)\n",
    "    S_yy = np.sum(A_y**2) / (n**3)\n",
    "    \n",
    "    if S_xx * S_yy == 0.:\n",
    "        corr = 0.\n",
    "    else:\n",
    "        corr = np.sqrt( S_xy / np.sqrt(S_xx * S_yy) )\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def get_equi_features(X):\n",
    "    # X is 2-d array\n",
    "    \n",
    "    n, p = X.shape\n",
    "    scale = np.sqrt(np.sum(X**2, axis=0))\n",
    "    Xstd = X / scale\n",
    "    sigma = np.dot(Xstd.T, Xstd)\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    lambd_min = eigsh(sigma, k=1, which='SA')[0].squeeze()\n",
    "    sj = np.min([1., 2.*lambd_min])\n",
    "    sj = sj - 0.00001\n",
    "    \n",
    "    mat_s = np.diag([sj]*p)\n",
    "    A = 2*mat_s - sj*sj*sigma_inv\n",
    "    C = np.linalg.cholesky(A).T\n",
    "    \n",
    "    Xn = np.random.randn(n, p)\n",
    "    XX = np.hstack([Xstd, Xn])\n",
    "    XXo = orthonormalize(XX)\n",
    "    U = XXo[:,range(p,2*p)]\n",
    "    \n",
    "    Xnew = np.dot(Xstd,  np.eye(p) - sigma_inv*sj) + np.dot(U,C)\n",
    "    return Xnew\n",
    "\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "X_knockoff = get_equi_features(X)\n",
    "\n",
    "X_knockoff_df = pd.DataFrame(X_knockoff)\n",
    "column_names = ['radius1', 'texture1', 'perimeter1', \n",
    "                'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1',\n",
    "                'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', \n",
    "                'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "                'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', \n",
    "                'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "                'symmetry3', 'fractal_dimension3']\n",
    "X_knockoff_df.columns = column_names\n",
    "feature = pd.concat([X,X_knockoff_df],axis = 1)\n",
    "dataset1 =  pd.concat([feature,data['Y']],axis = 1)\n",
    "dataset1\n",
    "# dataset1.to_csv('dataset1_for_DeepPINK.csv', index=False)\n",
    "\n",
    "lambda_array = np.zeros((60, 60))\n",
    "lambda_array2 = np.zeros((60, 1))\n",
    "input_dim = 60\n",
    "\n",
    "# Use tqdm for a one-line progress bar\n",
    "for i in tqdm(np.arange(0, 1, 0.01)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(60, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i)))\n",
    "    #model.add(layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(i)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(feature, Y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    first_layer = model.layers[0]\n",
    "    weights, biases = first_layer.get_weights()\n",
    "    \n",
    "    for j in range(min(len(weights), len(lambda_array))):\n",
    "        for n in range(min(len(weights[j]), len(lambda_array[j]))):\n",
    "            if abs(weights[j][n]) < 5e-4 and lambda_array[j][n] == 0:\n",
    "                lambda_array[j][n] = i\n",
    "    \n",
    "    # Calculate the Zi in second layer\n",
    "    second_layer = model.layers[1]\n",
    "    weights, biases = second_layer.get_weights()\n",
    "    #print(f\"Layer: {layer.name}, Weights: {weights}\")\n",
    "#     print(weights)\n",
    "#     for j in range(len(weights)):\n",
    "#         for n in range(len(weights[j])):\n",
    "#             if abs(weights[j][n]) < 5e-4 and lambda_array2[j][n] == 0 :\n",
    "# #                 print(j,n)\n",
    "#                 lambda_array2[j][n] = i\n",
    "print(lambda_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:07:59.199337Z",
     "iopub.status.busy": "2023-12-07T12:07:59.198866Z",
     "iopub.status.idle": "2023-12-07T12:07:59.207352Z",
     "shell.execute_reply": "2023-12-07T12:07:59.206116Z",
     "shell.execute_reply.started": "2023-12-07T12:07:59.199301Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_vars1 = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0,selected_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:07:59.210426Z",
     "iopub.status.busy": "2023-12-07T12:07:59.209863Z",
     "iopub.status.idle": "2023-12-07T12:07:59.239614Z",
     "shell.execute_reply": "2023-12-07T12:07:59.238263Z",
     "shell.execute_reply.started": "2023-12-07T12:07:59.210354Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "var_t = data.loc[:, ['radius1', 'texture1', 'perimeter1', \n",
    "                'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1',\n",
    "                'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', \n",
    "                'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "                'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', \n",
    "                'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "                'symmetry3', 'fractal_dimension3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['radius1', 'texture1', 'perimeter1', \n",
    "                'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1',\n",
    "                'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', \n",
    "                'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "                'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', \n",
    "                'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "                'symmetry3', 'fractal_dimension3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:07:59.243048Z",
     "iopub.status.busy": "2023-12-07T12:07:59.241899Z",
     "iopub.status.idle": "2023-12-07T12:09:30.654832Z",
     "shell.execute_reply": "2023-12-07T12:09:30.653598Z",
     "shell.execute_reply.started": "2023-12-07T12:07:59.243003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 8.102488684654237 s\n",
      "Average accuracy: 97.98245614035088 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,30, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:09:30.656644Z",
     "iopub.status.busy": "2023-12-07T12:09:30.656214Z",
     "iopub.status.idle": "2023-12-07T12:09:30.670025Z",
     "shell.execute_reply": "2023-12-07T12:09:30.669005Z",
     "shell.execute_reply.started": "2023-12-07T12:09:30.656614Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['radius3','texture3','symmetry3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['radius3','texture3','symmetry3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:09:30.673286Z",
     "iopub.status.busy": "2023-12-07T12:09:30.672871Z",
     "iopub.status.idle": "2023-12-07T12:09:30.687913Z",
     "shell.execute_reply": "2023-12-07T12:09:30.686996Z",
     "shell.execute_reply.started": "2023-12-07T12:09:30.673253Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_vars1 = [20,21,28]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0,selected_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:09:30.690134Z",
     "iopub.status.busy": "2023-12-07T12:09:30.689378Z",
     "iopub.status.idle": "2023-12-07T12:10:56.049779Z",
     "shell.execute_reply": "2023-12-07T12:10:56.048656Z",
     "shell.execute_reply.started": "2023-12-07T12:09:30.690097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 7.49768180847168 s\n",
      "Average accuracy: 96.49122807017545 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,3, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['texture1', 'smoothness3', 'concave_points2', 'symmetry2', 'radius3', 'perimeter3', 'concave_points3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['texture1', 'smoothness3', 'concave_points2', 'symmetry2', 'radius3', 'perimeter3', 'concave_points3']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars1 = [1,14,17,18,20,22,27]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0,selected_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 3.498571991920471 s\n",
      "Average accuracy: 98.2456140350877 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,7, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['perimeter2', 'smoothness1','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['perimeter2', 'smoothness1']], var_t['Y'], test_size=0.2, random_state=42)\n",
    "input_data = []\n",
    "output_data = []\n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars1 = [2,14]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0,selected_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Average running time: 2.837507462501526 s\n",
      "Average accuracy: 79.82456140350877 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,2, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWA_OML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars1 = [1,14,17,18,20,22,27,2,6,9,24,28,29,26,7,8,19,23,25,4,3]\n",
    "r,l1,l2 = reduce_weight(lambda_array,lambda_array2,0,selected_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['texture1','smoothness2','concave_points2','symmetry2','radius3', 'perimeter3', 'concave_points3','perimeter1', 'concavity1','fractal_dimension1','smoothness3',\n",
    "'symmetry3','fractal_dimension3','concavity3', 'concave_points1','symmetry1','fractal_dimension2','area3', 'compactness3','smoothness1','area1','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['texture1','smoothness2','concave_points2','symmetry2','radius3', 'perimeter3', 'concave_points3','perimeter1', 'concavity1','fractal_dimension1','smoothness3',\n",
    "'symmetry3','fractal_dimension3','concavity3', 'concave_points1','symmetry1','fractal_dimension2','area3', 'compactness3','smoothness1','area1']],\n",
    "                                                    var_t['Y'], test_size=0.2, random_state=42)\n",
    "# X_train = (X_train.values).reshape(-1,1)\n",
    "# X_test = (X_test.values).reshape(-1, 1)\n",
    "input_data = []\n",
    "output_data = [] \n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 2.954980158805847 s\n",
      "Average accuracy: 97.01754385964911 %\n"
     ]
    }
   ],
   "source": [
    "reduce_weight_prediction(X_train,y_train,X_test,y_test,21, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepPINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:39:49.101518Z",
     "iopub.status.busy": "2023-12-07T12:39:49.101030Z",
     "iopub.status.idle": "2023-12-07T12:39:49.116075Z",
     "shell.execute_reply": "2023-12-07T12:39:49.115146Z",
     "shell.execute_reply.started": "2023-12-07T12:39:49.101478Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['radius3', 'concave_points3', 'Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['radius3', 'concave_points3']],\n",
    "                                                    var_t['Y'], test_size=0.2, random_state=42)\n",
    "# X_train = (X_train.values).reshape(-1,1)\n",
    "# X_test = (X_test.values).reshape(-1, 1)\n",
    "input_data = []\n",
    "output_data = [] \n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:39:51.661896Z",
     "iopub.status.busy": "2023-12-07T12:39:51.661202Z",
     "iopub.status.idle": "2023-12-07T12:41:15.679406Z",
     "shell.execute_reply": "2023-12-07T12:41:15.678221Z",
     "shell.execute_reply.started": "2023-12-07T12:39:51.661858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Average running time: 8.36764407157898 s\n",
      "Average accuracy: 96.49122807017545 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:16:33.291910Z",
     "iopub.status.busy": "2023-12-07T12:16:33.291472Z",
     "iopub.status.idle": "2023-12-07T12:16:33.310183Z",
     "shell.execute_reply": "2023-12-07T12:16:33.308812Z",
     "shell.execute_reply.started": "2023-12-07T12:16:33.291877Z"
    }
   },
   "outputs": [],
   "source": [
    "var_t = data.loc[:, ['radius1', 'texture1','compactness1','concavity1','concave_points1','concave_points2','perimeter3','area3','Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(var_t[['radius1', 'texture1','compactness1','concavity1','concave_points1','concave_points2','perimeter3','area3']],\n",
    "                                                    var_t['Y'], test_size=0.2, random_state=42)\n",
    "# X_train = (X_train.values).reshape(-1,1)\n",
    "# X_test = (X_test.values).reshape(-1, 1)\n",
    "input_data = []\n",
    "output_data = [] \n",
    "input_test =  []\n",
    "output_test = []\n",
    "for i in X_train.values:\n",
    "    input_data.append(i)\n",
    "for i in y_train.values:  \n",
    "    output_data.append(i)\n",
    "for i in X_test.values:\n",
    "    input_test.append(i)\n",
    "for i in y_test.values:\n",
    "    output_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:37:47.784662Z",
     "iopub.status.busy": "2023-12-07T12:37:47.783734Z",
     "iopub.status.idle": "2023-12-07T12:39:10.784979Z",
     "shell.execute_reply": "2023-12-07T12:39:10.783624Z",
     "shell.execute_reply.started": "2023-12-07T12:37:47.784622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Average running time: 8.26431736946106 s\n",
      "Average accuracy: 95.78947368421053 %\n"
     ]
    }
   ],
   "source": [
    "normal_prediction(X_train,y_train,X_test,y_test,np.shape(var_t)[1]-1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4055662,
     "sourceId": 7047826,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
