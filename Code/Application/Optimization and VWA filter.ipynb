{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlotte\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import NeuralNet, train_model, predict,ProximalSGD,accuracy\n",
    "from knockoff import create_knockoff_variable\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    #Set the parameters are consistent when the model is initialized\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 30\n",
    "hidden_size_data = 60\n",
    "hidden_size = 60\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('cancerdata_feature.csv')\n",
    "data = df.rename(columns={\n",
    "    'Column1': 'radius1', 'Column2': 'texture1', 'Column3': 'perimeter1', \n",
    "    'Column4': 'area1', 'Column5': 'smoothness1', 'Column6': 'compactness', \n",
    "    'Column7': 'concavity1', 'Column8': 'concave_points1', 'Column9': 'symmetry1', \n",
    "    'Column10': 'fractal_dimension1', 'Column11': 'radius2', 'Column12': 'texture2', \n",
    "    'Column13': 'perimeter2', 'Column14': 'area2', 'Column15': 'smoothness2', \n",
    "    'Column16': 'compactness2', 'Column17': 'concavity2', 'Column18': 'concave_points2',\n",
    "    'Column19': 'symmetry2', 'Column20': 'fractal_dimension2', 'Column21': 'radius3', \n",
    "    'Column22': 'texture3', 'Column23': 'perimeter3', 'Column24': 'area3', \n",
    "    'Column25': 'smoothness3', 'Column26': 'compactness3', 'Column27': 'concavity3', \n",
    "    'Column28': 'concave_points3', 'Column29': 'symmetry3', 'Column30': 'fractal_dimension3'\n",
    "})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n",
    "y_df = pd.read_csv('cancerdata_Y.csv')\n",
    "\n",
    "y_df['Y'] = y_df['Y'].replace({'B': 0, 'M': 1})\n",
    "\n",
    "data_normalized['Y'] = y_df['Y']\n",
    "data = data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create knockoff variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "# X= (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    " \n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "knockoff_creator = create_knockoff_variable()\n",
    "X_knockoff = knockoff_creator.get_equi_features(X)\n",
    "# X_knockoff = (X_knockoff - X_knockoff.min(axis=0)) / (X_knockoff.max(axis=0) - X_knockoff.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>var_k21</th>\n",
       "      <th>var_k22</th>\n",
       "      <th>var_k23</th>\n",
       "      <th>var_k24</th>\n",
       "      <th>var_k25</th>\n",
       "      <th>var_k26</th>\n",
       "      <th>var_k27</th>\n",
       "      <th>var_k28</th>\n",
       "      <th>var_k29</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>0.085438</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.096793</td>\n",
       "      <td>0.086753</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>0.078790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>0.069187</td>\n",
       "      <td>0.082327</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>0.058920</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>0.041303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037910</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>0.070829</td>\n",
       "      <td>0.046311</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>0.039343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.031330</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>0.088762</td>\n",
       "      <td>0.127436</td>\n",
       "      <td>0.084528</td>\n",
       "      <td>0.081533</td>\n",
       "      <td>0.145202</td>\n",
       "      <td>0.145017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.026394</td>\n",
       "      <td>0.048932</td>\n",
       "      <td>0.052169</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040149</td>\n",
       "      <td>0.074205</td>\n",
       "      <td>0.085466</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>0.049894</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073162</td>\n",
       "      <td>0.066011</td>\n",
       "      <td>0.072558</td>\n",
       "      <td>0.029649</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.039445</td>\n",
       "      <td>0.051687</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062124</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.043427</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.042703</td>\n",
       "      <td>0.042206</td>\n",
       "      <td>0.045354</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076045</td>\n",
       "      <td>0.085183</td>\n",
       "      <td>0.076356</td>\n",
       "      <td>0.060413</td>\n",
       "      <td>0.127395</td>\n",
       "      <td>0.114868</td>\n",
       "      <td>0.084465</td>\n",
       "      <td>0.071434</td>\n",
       "      <td>0.084922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.037418</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius1  texture1  perimeter1     area1  smoothness1  compactness1  \\\n",
       "0    0.521037  0.022658    0.545989  0.363733     0.593753      0.792037   \n",
       "1    0.643144  0.272574    0.615783  0.501591     0.289880      0.181768   \n",
       "2    0.601496  0.390260    0.595743  0.449417     0.514309      0.431017   \n",
       "3    0.210090  0.360839    0.233501  0.102906     0.811321      0.811361   \n",
       "4    0.629893  0.156578    0.630986  0.489290     0.430351      0.347893   \n",
       "..        ...       ...         ...       ...          ...           ...   \n",
       "564  0.690000  0.428813    0.678668  0.566490     0.526948      0.296055   \n",
       "565  0.622320  0.626987    0.604036  0.474019     0.407782      0.257714   \n",
       "566  0.455251  0.621238    0.445788  0.303118     0.288165      0.254340   \n",
       "567  0.644564  0.663510    0.665538  0.475716     0.588336      0.790197   \n",
       "568  0.036869  0.501522    0.028540  0.015907     0.000000      0.074351   \n",
       "\n",
       "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n",
       "0      0.703140         0.731113   0.686364            0.605518  ...   \n",
       "1      0.203608         0.348757   0.379798            0.141323  ...   \n",
       "2      0.462512         0.635686   0.509596            0.211247  ...   \n",
       "3      0.565604         0.522863   0.776263            1.000000  ...   \n",
       "4      0.463918         0.518390   0.378283            0.186816  ...   \n",
       "..          ...              ...        ...                 ...  ...   \n",
       "564    0.571462         0.690358   0.336364            0.132056  ...   \n",
       "565    0.337395         0.486630   0.349495            0.113100  ...   \n",
       "566    0.216753         0.263519   0.267677            0.137321  ...   \n",
       "567    0.823336         0.755467   0.675253            0.425442  ...   \n",
       "568    0.000000         0.000000   0.266162            0.187026  ...   \n",
       "\n",
       "      var_k21   var_k22   var_k23   var_k24   var_k25   var_k26   var_k27  \\\n",
       "0    0.015118  0.085178  0.085438  0.058326  0.096793  0.086753  0.084118   \n",
       "1    0.031644  0.069187  0.082327  0.033843  0.024583  0.029432  0.058920   \n",
       "2    0.037910  0.065067  0.070829  0.046311  0.060284  0.055310  0.076889   \n",
       "3    0.040393  0.031330  0.017648  0.088762  0.127436  0.084528  0.081533   \n",
       "4    0.012823  0.064862  0.065068  0.043022  0.026394  0.048932  0.052169   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564  0.040149  0.074205  0.085466  0.044444  0.028495  0.049894  0.070077   \n",
       "565  0.073162  0.066011  0.072558  0.029649  0.025348  0.039445  0.051687   \n",
       "566  0.062124  0.049200  0.043427  0.027179  0.042703  0.042206  0.045354   \n",
       "567  0.076045  0.085183  0.076356  0.060413  0.127395  0.114868  0.084465   \n",
       "568  0.051026  0.005482  0.003641  0.011987  0.005362 -0.000588  0.000303   \n",
       "\n",
       "      var_k28   var_k29  Y  \n",
       "0    0.086150  0.078790  1  \n",
       "1    0.034146  0.041303  1  \n",
       "2    0.058908  0.039343  1  \n",
       "3    0.145202  0.145017  1  \n",
       "4    0.023266  0.026131  1  \n",
       "..        ...       ... ..  \n",
       "564  0.013654  0.020282  1  \n",
       "565  0.029235  0.014601  1  \n",
       "566  0.019231  0.028252  1  \n",
       "567  0.071434  0.084922  1  \n",
       "568  0.037418  0.018580  0  \n",
       "\n",
       "[569 rows x 61 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_knockoff_df = pd.DataFrame(X_knockoff,columns= [f'var_k{i}' for i in range(input_size)])\n",
    "feature = pd.concat([X,X_knockoff_df],axis = 1)\n",
    "dataset1 =  pd.concat([feature,data['Y']],axis = 1)\n",
    "dataset1\n",
    "# dataset1.to_csv(\"Simulationdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_W1(lambda_array,num_x):\n",
    "    row_sums1 = np.sum(lambda_array, axis=1)\n",
    "    W1 = []\n",
    "    for i in range(0,int(0.5*len(row_sums1)),1):\n",
    "        if row_sums1[i]>=row_sums1[i+num_x]:\n",
    "            W1.append(row_sums1[i])\n",
    "        else:\n",
    "            W1.append(-row_sums1[i+num_x])\n",
    "    return W1,row_sums1\n",
    "\n",
    "def compute_W2(model, row_sums1, num_x):\n",
    "    para = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and 'weight' in name:\n",
    "            para.append(param.data)\n",
    "\n",
    "\n",
    "    result = para[0]\n",
    "    for i in range(1, len(para)):\n",
    "        if i == (len(para) - 1):\n",
    "            result = torch.matmul(result.t(), para[i].reshape(-1, 1))\n",
    "        else:\n",
    "            result = torch.matmul(result.t(), para[i])\n",
    "    \n",
    "    g =[]\n",
    "    for i in range(len(result)):\n",
    "        g.append(result[i][0].cpu().numpy() * row_sums1[i]*10)\n",
    "  \n",
    "    W2= []\n",
    " \n",
    "    for i in range(0,int(0.5*len(g)),1):\n",
    "        W2.append(abs(g[i])-abs(g[i+num_x]))\n",
    "    return W2,g\n",
    "\n",
    "def select_variables(W,target_q):\n",
    "    T = []\n",
    "    for i in W:\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        t = abs(i)\n",
    "        for j in W:\n",
    "            if j < -t:\n",
    "                count1 = count1+1\n",
    "    \n",
    "            if j >= t:\n",
    "                count2 = count2 +1\n",
    "        q = (count1)/(max(count2,1))\n",
    "\n",
    "        if q <= target_q:\n",
    "            T.append(t)\n",
    "    threshold = min(T)\n",
    "    selected_vars = [i+1 for i in range(len(W)) if W[i] >= threshold]\n",
    "    return selected_vars, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Selected Variables: [1, 2, 3, 7, 8, 9, 10, 15, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Selected Variables: [3, 5, 7, 9, 10, 13, 14, 16, 18, 19, 21, 22, 23, 24, 27, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Selected Variables: [6, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Selected Variables: [7, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 - Selected Variables: [21, 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 - Selected Variables: [3, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 - Selected Variables: [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8 - Selected Variables: [2, 4, 12, 14, 15, 19, 23, 25, 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9 - Selected Variables: [2, 3, 7, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10 - Selected Variables: [2, 8, 10, 11, 18, 21, 22, 24, 25, 27, 28, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y.apply(pd.to_numeric, errors='coerce')\n",
    "y_float = (Y.values).astype(float) \n",
    "Y_tensor = torch.tensor(y_float, dtype=torch.float32).view(-1, 1).to(device)\n",
    "feature_tensor = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "c = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "# Y_tensor = Y_tensor.view(-1, 1) \n",
    "lambda_all = []\n",
    "all_selected_vars = []\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "\n",
    "for n in range(10):\n",
    "    lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "    for i in tqdm(np.arange(0,0.01,0.0001)):\n",
    "        net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "        optimizer = ProximalSGD(net1.parameters(), lr=0.01, l1_lambda=i)\n",
    "        train_model(net1, feature_tensor, Y_tensor, criterion, optimizer, epochs=50)\n",
    "        weight = next(net1.named_parameters())[1].data.t()\n",
    "        for j in range(len(lambda_array1)):\n",
    "            for k in range(len(lambda_array1[j])):\n",
    "                if abs(weight[j][k])==0 and lambda_array1[j][k] == 0:\n",
    "                    lambda_array1[j][k] = i\n",
    "    lambda_all.append(lambda_array1)\n",
    "    W1, _ = compute_W1(lambda_array1, input_size)\n",
    "    selected_vars, _ = select_variables(W1, 0.1)\n",
    "    print(f\"Model {n + 1} - Selected Variables:\", selected_vars)\n",
    "    all_selected_vars.append(selected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected variables and their counts:\n",
      "Variable: 2, Count: 5\n",
      "Variable: 15, Count: 5\n",
      "Variable: 18, Count: 5\n",
      "Variable: 19, Count: 5\n",
      "Variable: 21, Count: 5\n",
      "Variable: 23, Count: 5\n",
      "Variable: 28, Count: 5\n",
      "Variable: 3, Count: 4\n",
      "Variable: 7, Count: 4\n",
      "Variable: 10, Count: 4\n",
      "Variable: 25, Count: 4\n",
      "Variable: 29, Count: 4\n",
      "Variable: 30, Count: 4\n",
      "Variable: 27, Count: 4\n",
      "Variable: 8, Count: 3\n",
      "Variable: 9, Count: 3\n",
      "Variable: 20, Count: 3\n",
      "Variable: 24, Count: 3\n",
      "Variable: 11, Count: 3\n",
      "Variable: 26, Count: 3\n",
      "Variable: 1, Count: 2\n",
      "Variable: 5, Count: 2\n",
      "Variable: 14, Count: 2\n",
      "Variable: 16, Count: 2\n",
      "Variable: 22, Count: 2\n",
      "Variable: 6, Count: 2\n",
      "Variable: 4, Count: 2\n",
      "Variable: 12, Count: 2\n",
      "Variable: 13, Count: 1\n",
      "Variable: 17, Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_selected_vars(all_vars):\n",
    "    flat_vars = [item for sublist in all_vars for item in sublist]\n",
    "    var_counts = Counter(flat_vars)\n",
    "    sorted_vars = sorted(var_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_vars\n",
    "final_selected_vars = aggregate_selected_vars(all_selected_vars)\n",
    "\n",
    "\n",
    "print(\"Final selected variables and their counts:\")\n",
    "for var, count in final_selected_vars:\n",
    "    print(f\"Variable: {var}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Selected Variables: [2, 3, 4, 5, 8, 9, 15, 19, 20, 22, 24, 25, 27, 28, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Selected Variables: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Selected Variables: [7, 14, 15, 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Selected Variables: [3, 5, 6, 10, 20, 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 - Selected Variables: [9, 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 - Selected Variables: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 - Selected Variables: [7, 12, 15, 18, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8 - Selected Variables: [3, 4, 5, 8, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9 - Selected Variables: [1, 2, 3, 4, 5, 6, 12, 15, 17, 18, 19, 20, 21, 26, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10 - Selected Variables: [3, 15, 19, 21, 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y.apply(pd.to_numeric, errors='coerce')\n",
    "y_float = (Y.values).astype(float) \n",
    "Y_tensor = torch.tensor(y_float, dtype=torch.float32).view(-1, 1).to(device)\n",
    "feature_tensor = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "c = torch.tensor(feature.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "# Y_tensor = Y_tensor.view(-1, 1) \n",
    "lambda_all = []\n",
    "all_selected_vars = []\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "\n",
    "for n in range(10):\n",
    "    lambda_array1 = np.zeros((input_size*2,hidden_size))\n",
    "    for i in tqdm(np.arange(0,0.1,0.001)):\n",
    "        #(0,0.09,0.0009\n",
    "        net1 = NeuralNet([input_size*2, hidden_size, output_size]).to(device)\n",
    "        optimizer = ProximalSGD(net1.parameters(), lr=0.01, l1_lambda=i)\n",
    "        train_model(net1, feature_tensor, Y_tensor, criterion, optimizer, epochs=50)\n",
    "        weight = next(net1.named_parameters())[1].data.t()\n",
    "        for j in range(len(lambda_array1)):\n",
    "            for k in range(len(lambda_array1[j])):\n",
    "                if abs(weight[j][k])==0 and lambda_array1[j][k] == 0:\n",
    "                    lambda_array1[j][k] = i\n",
    "    lambda_all.append(lambda_array1)\n",
    "    W1, row_sums1 = compute_W1(lambda_all[n],input_size)\n",
    "    W2, _ = compute_W2(net1,row_sums1,input_size)\n",
    "    selected_vars, _ = select_variables(W2, 0.1)\n",
    "    print(f\"Model {n + 1} - Selected Variables:\", selected_vars)\n",
    "    all_selected_vars.append(selected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected variables and their counts:\n",
      "Variable: 15, Count: 6\n",
      "Variable: 3, Count: 5\n",
      "Variable: 5, Count: 4\n",
      "Variable: 4, Count: 3\n",
      "Variable: 19, Count: 3\n",
      "Variable: 20, Count: 3\n",
      "Variable: 24, Count: 3\n",
      "Variable: 27, Count: 3\n",
      "Variable: 23, Count: 3\n",
      "Variable: 26, Count: 3\n",
      "Variable: 18, Count: 3\n",
      "Variable: 21, Count: 3\n",
      "Variable: 2, Count: 2\n",
      "Variable: 8, Count: 2\n",
      "Variable: 9, Count: 2\n",
      "Variable: 22, Count: 2\n",
      "Variable: 25, Count: 2\n",
      "Variable: 28, Count: 2\n",
      "Variable: 30, Count: 2\n",
      "Variable: 7, Count: 2\n",
      "Variable: 14, Count: 2\n",
      "Variable: 6, Count: 2\n",
      "Variable: 12, Count: 2\n",
      "Variable: 17, Count: 2\n",
      "Variable: 10, Count: 1\n",
      "Variable: 13, Count: 1\n",
      "Variable: 16, Count: 1\n",
      "Variable: 29, Count: 1\n",
      "Variable: 1, Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_selected_vars(all_vars):\n",
    "    flat_vars = [item for sublist in all_vars for item in sublist]\n",
    "    var_counts = Counter(flat_vars)\n",
    "    sorted_vars = sorted(var_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_vars\n",
    "final_selected_vars = aggregate_selected_vars(all_selected_vars)\n",
    "\n",
    "\n",
    "print(\"Final selected variables and their counts:\")\n",
    "for var, count in final_selected_vars:\n",
    "    print(f\"Variable: {var}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### OML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Variable: 2, Count: 7\n",
    "Variable: 15, Count: 11\n",
    "Variable: 18, Count: 11\n",
    "Variable: 19, Count: 8\n",
    "Variable: 21, Count: 11\n",
    "Variable: 23, Count: 6\n",
    "Variable: 28, Count: 7\n",
    "Variable: 3, Count: 9\n",
    "Variable: 7, Count: 6\n",
    "Variable: 10, Count: 5\n",
    "Variable: 25, Count: 6\n",
    "Variable: 29, Count: 5\n",
    "Variable: 30, Count: 6\n",
    "Variable: 27, Count: 7\n",
    "Variable: 8, Count: 5\n",
    "Variable: 9, Count: 5\n",
    "Variable: 20, Count: 6\n",
    "Variable: 24, Count: 6\n",
    "Variable: 26, Count: 6\n",
    "Variable: 5, Count: 6\n",
    "Variable: 4, Count: 5\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
